WEBVTT

NOTE
Transcription provided by Deepgram
Request Id: 999584c7-c3b1-43c2-8e2f-3cf10ddce8b3
Created: 2025-05-15T19:02:31.088Z
Duration: 3328.6792
Channels: 1

00:00:02.640 --> 00:00:06.640
Talks about learning technology often center on technology.

00:00:07.280 --> 00:00:09.280
So instead, I'd like to begin by asking:

00:00:09.840 --> 00:00:13.840
What do you want learning to be like

00:00:12.665 --> 00:00:15.545
for yourself? If you could just snap your

00:00:15.545 --> 00:00:19.465
fingers and have the ideal perfect learning environment,

00:00:19.785 --> 00:00:23.865
what would that be like? One way to

00:00:23.865 --> 00:00:26.265
start getting at this question is to ask,

00:00:27.190 --> 00:00:31.910
what were the most rewarding high growth periods

00:00:31.910 --> 00:00:35.910
of your life? I've noticed two patterns when

00:00:35.910 --> 00:00:39.605
I ask people this question. First, people will

00:00:39.605 --> 00:00:41.205
tell me about a period in their life

00:00:41.205 --> 00:00:44.565
where they learned a ton, but where learning

00:00:44.565 --> 00:00:48.085
wasn't the point. Instead, they were totally immersed

00:00:48.085 --> 00:00:49.845
in some project with a great deal of

00:00:49.845 --> 00:00:52.885
personal meaning, like a scrappy startup or a

00:00:52.885 --> 00:00:56.260
research project or an artistic urge or just

00:00:56.260 --> 00:01:00.420
a fiery curiosity. And a lot of learning

00:01:00.420 --> 00:01:02.820
happened just along the way. They learned whatever

00:01:02.820 --> 00:01:04.740
they needed. They dove in. They got their

00:01:04.740 --> 00:01:09.915
hands dirty. Secondly, in these stories, learning really

00:01:10.075 --> 00:01:15.675
worked. People emerged feeling transformed, newly capable, filled

00:01:15.675 --> 00:01:17.915
with insights that remained with them years later.

00:01:19.570 --> 00:01:21.650
These stories are so vivid in part because

00:01:21.650 --> 00:01:26.210
learning rarely feels this way. People are often

00:01:26.210 --> 00:01:28.210
telling me somewhat wistfully about an experience that

00:01:28.210 --> 00:01:31.170
occurred years or decades earlier. Learning rarely feels

00:01:31.170 --> 00:01:34.265
so subordinated to an authentic pursuit. Often if

00:01:34.265 --> 00:01:36.345
we try to just dive in, we dive

00:01:36.345 --> 00:01:38.425
into a brick wall, or we find ourselves

00:01:38.425 --> 00:01:41.465
uneasily cargo culting others without any real understanding

00:01:41.465 --> 00:01:44.745
of what's actually going on. So why can't

00:01:44.745 --> 00:01:48.080
we just dive in all the time? Instead,

00:01:48.080 --> 00:01:49.600
it often feels like we have to put

00:01:49.600 --> 00:01:51.680
our aims on hold while we go do

00:01:51.680 --> 00:01:55.840
some homework and learn properly. And worse, learning

00:01:55.840 --> 00:01:59.280
so often just doesn't really work. We take

00:01:59.280 --> 00:02:02.095
the class, we read the book, And then

00:02:02.095 --> 00:02:03.295
when we try to put that knowledge into

00:02:03.295 --> 00:02:06.575
practice, we find that it's fragile. It doesn't

00:02:06.575 --> 00:02:10.255
transfer well. Worse, we'll often find that we've

00:02:10.255 --> 00:02:11.695
forgotten half of it by the time we

00:02:11.695 --> 00:02:14.255
try to use it. Why does learning so

00:02:14.255 --> 00:02:19.080
often fail to actually work? These questions connect

00:02:19.080 --> 00:02:21.080
to an age old conflict among educators and

00:02:21.080 --> 00:02:24.280
learning scientists between implicit learning, also known as

00:02:24.280 --> 00:02:28.040
discovery learning, inquiry learning, situated learning, and guided

00:02:28.040 --> 00:02:30.760
learning, which is often represented by cognitive scientists

00:02:30.760 --> 00:02:32.600
of the kind we find here at UCSD.

00:02:33.695 --> 00:02:35.855
Advocates of implicit learning methods argue that we

00:02:35.855 --> 00:02:40.175
should prioritize discovery, motivation, authentic involvement, and being

00:02:40.175 --> 00:02:43.135
situated in a community of practice. In the

00:02:43.135 --> 00:02:46.175
opposing camp, cognitive psychologists argue that you really

00:02:46.175 --> 00:02:47.855
do need to pay attention to the architecture

00:02:47.855 --> 00:02:50.360
of cognition, to long term memory, to procedural

00:02:50.360 --> 00:02:53.800
fluency, and to scaffold appropriately for cognitive load.

00:02:54.760 --> 00:02:57.640
In my view, each of these of view

00:02:58.120 --> 00:03:03.195
contains a lot of truth. And they also

00:03:03.195 --> 00:03:07.195
ignore each other to their detriment. Implicit learning

00:03:07.195 --> 00:03:10.875
aptly recognizes meaning and emotion but ignores the

00:03:10.875 --> 00:03:13.515
often decisive constraints of cognition what we need

00:03:13.515 --> 00:03:17.290
to actually make learning work. Guided learning advocates

00:03:17.290 --> 00:03:19.930
are focused on making learning work, and they

00:03:19.930 --> 00:03:23.450
sometimes succeed, but usually by sacrificing that purposeful

00:03:23.450 --> 00:03:25.690
sense of immersion that we love about those

00:03:25.690 --> 00:03:29.835
rewarding high growth periods. One obvious approach is

00:03:29.835 --> 00:03:32.715
to try compromise. Project based learning is a

00:03:32.715 --> 00:03:35.435
good representation of that. By creating a scaffolded

00:03:35.435 --> 00:03:37.595
series of projects, the suggestion is that we

00:03:37.595 --> 00:03:39.275
can get some of the benefits of implicit

00:03:39.275 --> 00:03:44.620
learning authenticity, motivation, transferability while also getting the

00:03:44.620 --> 00:03:47.500
instructional control and the cognitive awareness that might

00:03:47.500 --> 00:03:52.860
be typical of traditional courses. The trouble is

00:03:52.860 --> 00:03:54.620
that usually we get the worst of both

00:03:54.620 --> 00:03:57.915
worlds. I remember when I was in college,

00:03:57.915 --> 00:03:59.755
I was interested in three d game programming,

00:03:59.755 --> 00:04:01.275
so I signed up for a project based

00:04:01.275 --> 00:04:04.635
course on computer graphics. The trouble was that

00:04:04.635 --> 00:04:07.675
those projects weren't my projects. So a few

00:04:07.675 --> 00:04:10.260
weeks in, I ended up implementing array marching

00:04:10.260 --> 00:04:13.060
for more efficient bump mapping. And unfortunately, I

00:04:13.060 --> 00:04:15.220
was really just implementing some math that I

00:04:15.220 --> 00:04:16.660
was handed because this course was trying to

00:04:16.660 --> 00:04:18.500
take project based learning seriously. So there weren't

00:04:18.500 --> 00:04:21.700
long textbook readings, weren't long problem sets. But

00:04:21.700 --> 00:04:24.295
I didn't understand the math. What I ended

00:04:24.295 --> 00:04:25.575
up with was a project that I didn't

00:04:25.575 --> 00:04:29.895
care about implementing something I didn't understand. Instead,

00:04:29.895 --> 00:04:32.775
I suggest, we should take both views seriously.

00:04:33.255 --> 00:04:35.815
Find a way to synthesize the two. You

00:04:35.815 --> 00:04:39.415
really do want to make doing the thing

00:04:38.760 --> 00:04:42.040
the primary activity. But the realities of cognitive

00:04:42.040 --> 00:04:44.760
psychology mean that in many cases, you really

00:04:44.760 --> 00:04:48.280
do need explicit guidance, scaffolding, practice, intention and

00:04:48.280 --> 00:04:52.535
memory support. Learning by immersion works naturalistically when

00:04:52.535 --> 00:04:54.375
the material has a low enough complexity relative

00:04:54.375 --> 00:04:56.295
to your prior knowledge that you can successfully

00:04:56.295 --> 00:04:58.455
process it on the fly and when natural

00:04:58.455 --> 00:05:03.495
participation routinely reinforces everything important, giving you fluency.

00:05:04.295 --> 00:05:06.130
When those conditions aren't satisfied, which is most

00:05:06.130 --> 00:05:08.050
of the time, you will need some support.

00:05:08.530 --> 00:05:10.690
You want to just dive in. And you

00:05:10.690 --> 00:05:13.810
want learning to actually work. To make that

00:05:13.810 --> 00:05:15.970
happen, we need to infuse your authentic projects

00:05:15.970 --> 00:05:19.355
with guided support, where necessary, inspired by the

00:05:19.355 --> 00:05:21.755
best ideas from cognitive science. And if there's

00:05:21.755 --> 00:05:25.355
something that requires more focused, explicit learning, then

00:05:25.355 --> 00:05:27.595
you want those experiences to be utterly in

00:05:27.595 --> 00:05:32.220
service to your actual aims. Now I've been

00:05:32.220 --> 00:05:34.140
thinking about this synthesis for many years, and

00:05:34.140 --> 00:05:38.140
honestly, I've mostly been pretty stuck. Recently though,

00:05:38.140 --> 00:05:41.180
I've been thinking a lot about AI, which

00:05:41.420 --> 00:05:44.565
I know gets an eye roll. Certainly every

00:05:44.565 --> 00:05:47.605
mention of AI in education gets an eye

00:05:47.605 --> 00:05:50.645
roll from me. But I confess, the possibility

00:05:50.645 --> 00:05:53.445
of AI has helped me finally get what

00:05:53.445 --> 00:05:56.325
feels like some traction on this particular problem.

00:05:56.805 --> 00:05:58.325
So I'd like to share some of those

00:05:58.325 --> 00:06:02.020
early concepts today. We'll explore this possible synthesis

00:06:02.020 --> 00:06:05.700
through a story in six parts. Meet Sam.

00:06:06.340 --> 00:06:08.980
Sam studied computer science in university, and they're

00:06:08.980 --> 00:06:10.580
now working as a software engineer at a

00:06:10.580 --> 00:06:15.215
big tech company. But Sam is bored at

00:06:15.215 --> 00:06:18.255
their day job. Not everything is boring, though.

00:06:18.255 --> 00:06:20.335
Every time Sam sees a tweet announcing new

00:06:20.335 --> 00:06:23.215
results in brain computer interfaces, they're absolutely captivated.

00:06:23.535 --> 00:06:25.615
These projects seem so much more interesting than

00:06:25.615 --> 00:06:28.210
what they're doing by day. Sam pulls up

00:06:28.210 --> 00:06:31.010
the papers looking for some way to contribute,

00:06:31.010 --> 00:06:32.850
but they hit a brick wall with so

00:06:32.850 --> 00:06:36.850
many unfamiliar topics all at once. What if

00:06:36.850 --> 00:06:39.250
Sam could ask for help finding some meaningful

00:06:39.250 --> 00:06:43.855
way to start participating? With Sam's permission, our

00:06:43.855 --> 00:06:46.495
AI, and let's assume it's a local AI,

00:06:46.495 --> 00:06:48.335
can build up a huge amount of context

00:06:48.335 --> 00:06:51.375
about their background. From old documents on Sam's

00:06:51.375 --> 00:06:53.455
hard drive, our AI knows all about their

00:06:53.455 --> 00:06:56.000
university coursework. It can see their current skills

00:06:56.000 --> 00:06:58.560
through work projects. It knows something about Sam's

00:06:58.560 --> 00:07:02.240
interests through their browsing history. So it suggests

00:07:02.240 --> 00:07:04.400
a few ideas, and Sam is excited about

00:07:04.400 --> 00:07:06.880
the idea of reproducing the paper's data analysis.

00:07:06.880 --> 00:07:10.165
That seems to play to their strengths. They

00:07:10.165 --> 00:07:12.965
notice that the authors use a custom Python

00:07:12.965 --> 00:07:15.045
package to do their analysis, but that code

00:07:15.045 --> 00:07:17.685
was never published. And that seems intriguing. Sam

00:07:17.685 --> 00:07:20.645
has built open source tools before. Maybe they

00:07:20.645 --> 00:07:22.565
could contribute here by building an open source

00:07:22.565 --> 00:07:26.270
version of this signal processing pipeline. So Sam

00:07:26.270 --> 00:07:30.110
dives in. They've found an open access dataset,

00:07:30.590 --> 00:07:32.510
and they've taken the first steps to start

00:07:32.510 --> 00:07:36.190
working with it. Tools like Copilot help Sam

00:07:36.190 --> 00:07:38.190
get started. But to follow some of these

00:07:38.190 --> 00:07:40.345
signal processing steps, what Sam really needs here

00:07:40.345 --> 00:07:44.105
is something like Copilot, but with awareness of

00:07:44.105 --> 00:07:46.505
the paper in addition to the code and

00:07:46.505 --> 00:07:48.505
with context about what Sam's actually trying to

00:07:48.505 --> 00:07:53.145
do. This AI system isn't trapped in its

00:07:53.145 --> 00:07:55.350
own chat box or in the sidebar of

00:07:55.350 --> 00:07:57.750
one application. It can see what's going on

00:07:57.750 --> 00:08:01.030
across multiple applications, and it can propose actions

00:08:01.030 --> 00:08:05.190
across multiple applications. Sam can click that button

00:08:05.190 --> 00:08:07.750
to view a change set with the potential

00:08:07.750 --> 00:08:11.185
implementation. Here that is. And then they can

00:08:11.185 --> 00:08:14.545
continue the conversation, smoothly switching into the context

00:08:14.545 --> 00:08:17.345
of the code editor. Like, what is this

00:08:17.345 --> 00:08:21.985
axis equals one parameter? The explanation depends on

00:08:21.985 --> 00:08:24.910
context from the code editor, from the paper

00:08:24.910 --> 00:08:27.710
being implemented, and also the documentation that came

00:08:27.710 --> 00:08:30.510
with the data set Sam's working with. The

00:08:30.510 --> 00:08:34.350
AI underlines assumptions made based on specific information

00:08:34.350 --> 00:08:37.815
and turns those things into links. So Sam

00:08:37.815 --> 00:08:40.615
can click on that in this dataset link,

00:08:40.935 --> 00:08:42.935
and our AI opens the ReadMe to the

00:08:42.935 --> 00:08:46.455
relevant line. All this is to support our

00:08:46.455 --> 00:08:49.175
central aim, which is that Sam can immerse

00:08:49.175 --> 00:08:52.470
themselves as much as possible in what they're

00:08:52.470 --> 00:08:55.430
actually trying to do, but get the support

00:08:55.430 --> 00:08:59.270
they need to understand what they're doing. And

00:08:59.270 --> 00:09:01.190
that support doesn't have to just mean text.

00:09:03.045 --> 00:09:06.085
Sam next needs to implement a downsampling stage.

00:09:06.645 --> 00:09:10.165
And this time, guidance includes synthesized dynamic media

00:09:10.165 --> 00:09:12.885
so that Sam can understand what downsampling does

00:09:12.885 --> 00:09:16.760
through scaffolded immersion. Doesn't need to read an

00:09:16.760 --> 00:09:19.160
abstract explanation and try to imagine what that

00:09:19.160 --> 00:09:21.480
would do to different signals. Instead, as they

00:09:21.480 --> 00:09:23.800
try different sampling rates, real time feedback can

00:09:23.800 --> 00:09:26.040
help them internalize the effect on different signals.

00:09:28.645 --> 00:09:30.485
By playing with the dynamic media, Sam notices

00:09:30.485 --> 00:09:32.005
that some of the peaks are lost when

00:09:32.005 --> 00:09:36.565
the signal is downsampled. These dynamic media aren't

00:09:36.565 --> 00:09:39.445
trapped in the chat box. They're using the

00:09:39.445 --> 00:09:42.165
same input data and libraries that Sam is

00:09:42.165 --> 00:09:44.480
using in their notebook. So at any time,

00:09:44.480 --> 00:09:46.880
Sam can just view source to tinker with

00:09:46.880 --> 00:09:48.880
this figure or to use some of its

00:09:48.880 --> 00:09:55.840
code in their own notebook. Now Sam presses

00:09:55.840 --> 00:10:00.925
on. But as they dig into bandpass filters,

00:10:01.645 --> 00:10:03.325
the high level explanations they can get from

00:10:03.325 --> 00:10:06.445
these short chat interactions really just don't feel

00:10:06.445 --> 00:10:10.285
like enough. What is a frequency domain? What

00:10:10.285 --> 00:10:13.070
is a Nyquist rate? Sam can copy and

00:10:13.070 --> 00:10:15.390
paste some AI generated code all day, but

00:10:15.390 --> 00:10:17.790
they don't understand what's going on at all.

00:10:18.270 --> 00:10:20.750
A chat interface is just not a great

00:10:20.750 --> 00:10:24.910
medium for long form conceptual explanation. It's time

00:10:24.910 --> 00:10:29.445
here for something deeper. Now, our AI knows

00:10:29.445 --> 00:10:32.245
Sam's background and aims here, so it suggests

00:10:32.245 --> 00:10:35.285
an appropriate undergraduate text with a practical focus.

00:10:36.245 --> 00:10:39.250
And more importantly, the AI reassures Sam that

00:10:39.250 --> 00:10:41.810
they don't necessarily need to read this entire

00:10:41.810 --> 00:10:45.730
thousand page book right now. It focuses on

00:10:45.730 --> 00:10:48.290
Sam's goal here and suggests a range of

00:10:48.290 --> 00:10:51.090
accessible paths that Sam can choose according to

00:10:51.090 --> 00:10:52.930
how deeply they would like to understand this

00:10:52.930 --> 00:10:56.455
material. The AI has made a personal map

00:10:56.455 --> 00:10:58.935
in the book's table of contents so that

00:10:58.935 --> 00:11:01.495
if Sam, for instance, just wants to understand

00:11:01.495 --> 00:11:04.375
what these filters are doing and why, there's

00:11:04.375 --> 00:11:06.695
a 25 page path for that. But if

00:11:06.695 --> 00:11:08.695
they want to know the mathematical background how

00:11:08.695 --> 00:11:11.280
these filters work, there's a deeper path. And

00:11:11.280 --> 00:11:12.560
if they want to actually be able to

00:11:12.560 --> 00:11:16.000
implement them themselves, there's an even deeper path.

00:11:16.160 --> 00:11:19.840
You can choose a journey here. When Sam

00:11:19.840 --> 00:11:21.920
digs into the book, you'll find notes from

00:11:21.920 --> 00:11:23.680
the AI at the start of each section

00:11:23.680 --> 00:11:26.335
and scattered throughout, which ground the material in

00:11:26.335 --> 00:11:30.495
Sam's context, Sam's project, Sam's purpose. This section

00:11:30.495 --> 00:11:31.855
will help you understand how to think about

00:11:31.855 --> 00:11:34.415
signals in terms of frequency spectra. That's what

00:11:34.415 --> 00:11:38.440
low pass filters manipulate. Sam is spending some

00:11:38.440 --> 00:11:40.200
time away from their project in a more

00:11:40.200 --> 00:11:43.640
traditionally instructional setting. But that doesn't mean the

00:11:43.640 --> 00:11:45.880
experience has to lose its connection to their

00:11:45.880 --> 00:11:50.920
authentic purpose. Incidentally, I've heard some technologists suggest

00:11:50.920 --> 00:11:52.600
that we should just use AI to synthesize

00:11:52.600 --> 00:11:55.985
the whole book. We'll get per person bespoke

00:11:55.985 --> 00:11:58.705
textbooks. But I think that there's actually a

00:11:58.705 --> 00:12:01.265
huge amount of value in having shared canonical

00:12:01.265 --> 00:12:03.505
artifacts. In any given field, there are key

00:12:03.505 --> 00:12:05.345
texts that we can all point to, and

00:12:05.345 --> 00:12:07.265
they form a common ground for the culture.

00:12:07.745 --> 00:12:09.860
I think we can preserve that by layering

00:12:09.860 --> 00:12:12.180
personalized context on top as a lens like

00:12:12.180 --> 00:12:16.420
this. In my ideal future, of course, our

00:12:16.420 --> 00:12:19.940
canonical shared artifacts are dynamic media, not digital

00:12:19.940 --> 00:12:23.115
representations of dead trees. But until all of

00:12:23.115 --> 00:12:25.995
our canonical works are rewritten as a transitional

00:12:25.995 --> 00:12:28.075
measure, we can at least wave our hands

00:12:28.075 --> 00:12:30.555
and imagine that our AI could synthesize dynamic

00:12:30.555 --> 00:12:34.235
media versions of figures like this one. Now,

00:12:34.235 --> 00:12:35.940
as Sam reads through the book, they can

00:12:35.940 --> 00:12:37.620
continue to engage with the text by asking

00:12:37.620 --> 00:12:40.580
questions as before, and our AI's responses will

00:12:40.580 --> 00:12:44.180
continue to be grounded in their project. As

00:12:44.180 --> 00:12:46.740
Sam highlights the text or makes comments about

00:12:46.740 --> 00:12:49.845
details which seem particularly important or surprising, those

00:12:49.845 --> 00:12:52.805
annotations won't end up trapped inside the PDF.

00:12:52.965 --> 00:12:55.285
Instead, they will feed into future discussions and

00:12:55.285 --> 00:12:59.045
practice, as we'll see later. In addition to

00:12:59.045 --> 00:13:01.925
Sam asking questions of the AI, the AI

00:13:01.925 --> 00:13:04.900
can insert questions for Sam to consider, again

00:13:04.900 --> 00:13:07.860
grounded in their project, to promote deeper processing

00:13:07.860 --> 00:13:11.700
of the material. And just as our AI

00:13:11.700 --> 00:13:13.700
guided Sam to the right sections of this

00:13:13.700 --> 00:13:16.260
thousand page book, it can point out which

00:13:16.260 --> 00:13:19.140
exercises might be most valuable, considering both Sam's

00:13:19.140 --> 00:13:23.835
background and their aims. Better, it can connect

00:13:23.835 --> 00:13:27.675
the exercises to Sam's aims so that aspirationally,

00:13:27.675 --> 00:13:31.035
doing those problems feels continuous with Sam's authentic

00:13:31.035 --> 00:13:34.635
practice. Even if the exercises do still feel

00:13:34.635 --> 00:13:38.210
somewhat decontextualized, Sam can at least feel more

00:13:38.210 --> 00:13:39.890
confident that the work is going to help

00:13:39.890 --> 00:13:43.890
them do what they want to do. So

00:13:43.890 --> 00:13:46.290
Sam ends the day with some rewarding progress

00:13:46.290 --> 00:13:48.930
on their project and a newfound understanding of

00:13:48.930 --> 00:13:52.015
quite a few topics. But this isn't yet

00:13:52.015 --> 00:13:56.095
robust knowledge. SAM has very little fluency. If

00:13:56.095 --> 00:13:58.255
they try to use this material seriously, they'll

00:13:58.255 --> 00:14:00.735
probably feel like they're standing on shaky ground.

00:14:01.455 --> 00:14:05.300
And more prosaically, they will probably forget much

00:14:05.300 --> 00:14:08.580
of what they just learned. So I'd like

00:14:08.580 --> 00:14:10.180
to focus on memory for a bit here.

00:14:10.900 --> 00:14:14.180
It's worth asking, why do we sometimes remember

00:14:14.180 --> 00:14:18.115
conceptual material and sometimes not? Often we take

00:14:18.115 --> 00:14:20.515
a class or read a book or even

00:14:20.515 --> 00:14:22.915
just look something up and find that a

00:14:22.915 --> 00:14:26.595
short time later, have retained almost nothing. But

00:14:26.595 --> 00:14:29.075
sometimes things seem to stick. Why is that?

00:14:30.870 --> 00:14:33.350
There are some easier cases. If you're learning

00:14:33.350 --> 00:14:34.790
something new in a domain that you know

00:14:34.790 --> 00:14:37.110
well, each new fact connects to lots of

00:14:37.110 --> 00:14:39.910
prior knowledge, and that creates more cues for

00:14:39.910 --> 00:14:43.785
recall and more opportunities for reinforcement. Likewise, if

00:14:43.785 --> 00:14:45.625
you're in some setting where you need that

00:14:45.625 --> 00:14:47.865
knowledge every single day, you will find that

00:14:47.865 --> 00:14:51.545
your memory becomes reliable pretty quickly. Conceptual material

00:14:51.545 --> 00:14:54.105
like what Sam just learned doesn't usually get

00:14:54.105 --> 00:14:57.960
reinforced every day like that. But sometimes the

00:14:57.960 --> 00:15:01.000
world conspires to give those memories the reinforcement

00:15:01.000 --> 00:15:04.920
it needs. Sometimes you read about a topic,

00:15:05.000 --> 00:15:07.480
and then later in that evening, that topic

00:15:07.480 --> 00:15:11.095
comes up in conversation with the collaborator. You

00:15:11.095 --> 00:15:12.855
have to retrieve what you learned, and that

00:15:12.855 --> 00:15:16.215
retrieval reinforces the memory. Then, maybe two days

00:15:16.215 --> 00:15:18.535
later, it comes up again. You need to

00:15:18.535 --> 00:15:21.575
recall that knowledge for a project. Each time

00:15:21.575 --> 00:15:23.735
you reinforce the memory this way, you forget

00:15:23.735 --> 00:15:26.370
it more slowly. Now perhaps a week can

00:15:26.370 --> 00:15:28.530
go by and you're still likely to remember,

00:15:28.770 --> 00:15:30.770
then maybe a few weeks, then a few

00:15:30.770 --> 00:15:34.530
months, and so on. With a surprisingly small

00:15:34.530 --> 00:15:37.170
number of retrievals, if they're placed close enough

00:15:37.170 --> 00:15:39.985
to avoid forgetting, you can retain that knowledge

00:15:39.985 --> 00:15:43.825
for months or years. By contrast, sometimes when

00:15:43.825 --> 00:15:45.905
you learn something, it doesn't come up again

00:15:45.905 --> 00:15:48.385
until, say, the next week. Then you try

00:15:48.385 --> 00:15:50.305
to retrieve the knowledge, but maybe it's already

00:15:50.305 --> 00:15:52.385
been forgotten. So you have to look it

00:15:52.385 --> 00:15:55.030
up. Looking it up doesn't reinforce your memory

00:15:55.030 --> 00:15:57.750
very much. And then if it doesn't come

00:15:57.750 --> 00:15:59.750
up again for a while longer, you may

00:15:59.750 --> 00:16:01.750
still not remember the next time. So you

00:16:01.750 --> 00:16:03.750
have to look it up again. And so

00:16:03.750 --> 00:16:07.270
on. The key insight here is that it's

00:16:07.270 --> 00:16:11.695
possible to arrange the timeline for yourself. And

00:16:11.695 --> 00:16:15.455
of course, courses sometimes do when each problem

00:16:15.455 --> 00:16:18.095
set consistently interleaves knowledge from the prior problem

00:16:18.095 --> 00:16:22.575
sets. But immersive learning and for that matter,

00:16:23.120 --> 00:16:26.160
most learning usually doesn't arrange this properly, so

00:16:26.160 --> 00:16:29.920
you usually forget a lot. What if this

00:16:29.920 --> 00:16:32.560
kind of reinforcement were woven into the grain

00:16:32.560 --> 00:16:37.565
of the learning region? Collaborator Michael Nielsen and

00:16:37.565 --> 00:16:40.685
I created a quantum computing primer, Quantum Country,

00:16:40.765 --> 00:16:44.525
to explore this idea. It's available for free

00:16:44.525 --> 00:16:47.165
online. If you head to quantum.country, you'll see

00:16:47.165 --> 00:16:48.605
what looks at first like a normal book.

00:16:53.370 --> 00:16:55.770
And after a few minutes of reading, the

00:16:55.770 --> 00:16:58.410
text is interrupted with a small set of

00:16:58.410 --> 00:17:02.410
review questions. They're designed to take just a

00:17:02.410 --> 00:17:04.965
few seconds each. Think the answer to yourself.

00:17:05.125 --> 00:17:06.885
Then mark whether or not you were able

00:17:06.885 --> 00:17:10.245
to answer correctly. And so far, these look

00:17:10.245 --> 00:17:13.925
like simple flashcards. But as we've discussed, even

00:17:13.925 --> 00:17:15.765
if you can answer these questions now, that

00:17:15.765 --> 00:17:17.285
doesn't mean you'll be able to in a

00:17:17.285 --> 00:17:19.730
few weeks or even in a few days.

00:17:20.370 --> 00:17:22.930
So notice these markings at the bottom of

00:17:22.930 --> 00:17:26.850
each question. These represent intervals. So you practice

00:17:26.850 --> 00:17:29.090
the questions while you're reading the text. Then

00:17:29.090 --> 00:17:30.930
one week later, you'll get an email that

00:17:30.930 --> 00:17:33.170
says, Hey, you have probably started to forget

00:17:33.435 --> 00:17:35.515
some of what you've learned. Do you want

00:17:35.515 --> 00:17:37.355
to take five minutes to quickly review that

00:17:37.355 --> 00:17:40.715
material again? Each time you answer successfully, the

00:17:40.715 --> 00:17:43.195
interval increases to a few weeks and a

00:17:43.195 --> 00:17:45.595
few months and so on. If you begin

00:17:45.595 --> 00:17:48.600
to forget, then the intervals tighten up to

00:17:48.600 --> 00:17:51.160
provide more reinforcement. Now you may have seen

00:17:51.160 --> 00:17:53.800
systems like this before. Language learners and medical

00:17:53.800 --> 00:17:56.120
students in particular often use tools called spaced

00:17:56.120 --> 00:17:59.400
repetition memory systems to remember vocabulary and basic

00:17:59.400 --> 00:18:03.285
facts. But the same cognitive mechanisms should work

00:18:03.285 --> 00:18:07.285
for more complex conceptual knowledge as well. There

00:18:07.285 --> 00:18:10.485
are 112 of these questions scattered throughout the

00:18:10.485 --> 00:18:12.565
first chapter of the book on that basis.

00:18:13.630 --> 00:18:15.870
Quantum country is a kind of new medium,

00:18:16.270 --> 00:18:19.230
a mnemonic medium, integrating a spaced repetition memory

00:18:19.230 --> 00:18:22.830
system with an explanatory text aspirationally to make

00:18:22.830 --> 00:18:25.230
it easier for people to absorb complex material

00:18:25.230 --> 00:18:29.375
reliably. We now have millions of practice data

00:18:29.375 --> 00:18:31.055
points, so we can start to see how

00:18:31.055 --> 00:18:34.495
well it's working. This plot shows the amount

00:18:34.495 --> 00:18:37.215
of time spent practicing on the x axis

00:18:37.215 --> 00:18:41.960
versus the reader's demonstrated retention that is, how

00:18:41.960 --> 00:18:43.480
long a reader was able to go without

00:18:43.480 --> 00:18:45.960
practicing and still answer at least 90% of

00:18:45.960 --> 00:18:49.880
questions correctly. These five dots represent the median

00:18:49.880 --> 00:18:53.400
user's first five repetitions for the first chapter.

00:18:54.545 --> 00:18:56.865
Notice that the y axis is logarithmic, so

00:18:56.865 --> 00:18:59.505
this straight line plot we're seeing here represents

00:18:59.505 --> 00:19:03.185
a very nice exponential growth. Each extra repetition,

00:19:03.185 --> 00:19:06.145
which is a constant extra time input, yields

00:19:06.145 --> 00:19:10.420
increasing output, I. E. Retention. And so in

00:19:10.420 --> 00:19:12.340
exchange for about an hour and a half

00:19:12.340 --> 00:19:15.060
of total practice, the median reader was able

00:19:15.060 --> 00:19:18.020
to correctly answer over 100 detailed questions about

00:19:18.020 --> 00:19:20.340
the first chapter after more than two months

00:19:20.340 --> 00:19:24.295
without any practice. Now, the first chapter takes

00:19:24.295 --> 00:19:26.695
most readers about four hours to read the

00:19:26.695 --> 00:19:29.655
first time. So this plot implies that an

00:19:29.655 --> 00:19:32.375
extra overhead of less than 50% in time

00:19:32.375 --> 00:19:36.535
commitment can yield months or years of detailed

00:19:36.535 --> 00:19:41.200
retention. It's also interesting to explore the counterfactual:

00:19:41.440 --> 00:19:43.360
how much would people have forgotten if they

00:19:43.360 --> 00:19:46.400
didn't have this extra reinforcement? So as an

00:19:46.400 --> 00:19:49.120
experiment, we removed nine questions from the first

00:19:49.120 --> 00:19:52.065
chapter for some readers and then covertly reinserted

00:19:52.065 --> 00:19:54.385
the questions one month later into their practice

00:19:54.385 --> 00:19:58.545
sessions. This graph shows what happened. These nine

00:19:58.545 --> 00:20:01.745
points represent those nine questions. The y axis

00:20:01.745 --> 00:20:03.745
shows the percentage of readers who are able

00:20:03.745 --> 00:20:06.060
to answer that correctly after one month with

00:20:06.060 --> 00:20:08.460
no support at all. You can see that

00:20:08.460 --> 00:20:10.780
some questions are harder than others. All the

00:20:10.780 --> 00:20:12.380
way over here on the left, one month

00:20:12.380 --> 00:20:14.380
later, the majority of readers missed the hardest

00:20:14.380 --> 00:20:17.340
three questions. And about thirty percent missed the

00:20:17.340 --> 00:20:20.060
middle three, about fifteen percent missed the easiest

00:20:20.060 --> 00:20:23.715
three. We can compare these to another group

00:20:23.715 --> 00:20:26.035
of users who got practice while reading the

00:20:26.035 --> 00:20:27.715
essay, like we saw in the video a

00:20:27.715 --> 00:20:30.595
moment ago. And for any questions they missed,

00:20:30.595 --> 00:20:32.035
they got a bonus round of practice the

00:20:32.035 --> 00:20:34.675
next day. Then these questions disappeared for a

00:20:34.675 --> 00:20:38.310
month, at which point we tested. These readers

00:20:38.310 --> 00:20:40.870
performed noticeably better, though a big chunk of

00:20:40.870 --> 00:20:43.430
them are still missing several of these questions.

00:20:44.550 --> 00:20:47.190
Now, here's one last group, like the previous

00:20:47.190 --> 00:20:49.925
one, except they got just one extra round

00:20:49.925 --> 00:20:52.005
of practice a week after reading the book.

00:20:52.245 --> 00:20:53.685
Then we tested them again at the one

00:20:53.685 --> 00:20:55.285
month mark, and that's what you're seeing here.

00:20:55.845 --> 00:20:58.725
Each question takes six seconds on average to

00:20:58.725 --> 00:21:00.805
answer. So this is less than a minute

00:21:00.805 --> 00:21:02.965
of extra practice in total for these nine

00:21:02.965 --> 00:21:05.440
questions. But now, for all of these questions,

00:21:05.440 --> 00:21:07.280
at least 90% of readers were able to

00:21:07.280 --> 00:21:11.120
answer correctly. Of course, some readers have a

00:21:11.120 --> 00:21:14.640
much easier time than others. So the left

00:21:14.640 --> 00:21:17.520
plot here focuses on the bottom quartile of

00:21:17.520 --> 00:21:20.375
users. That is, the readers who missed the

00:21:20.375 --> 00:21:22.135
most questions while they were first reading the

00:21:22.135 --> 00:21:24.535
essay. Notice that I've had to lengthen the

00:21:24.535 --> 00:21:27.015
y axis downwards here because we can see

00:21:27.015 --> 00:21:29.815
that without any practice at all, most of

00:21:29.815 --> 00:21:32.055
these people in the bottom quartile forgot two

00:21:32.055 --> 00:21:35.970
thirds of these held out questions. If they

00:21:35.970 --> 00:21:39.650
only had in essay practice, roughly half of

00:21:39.650 --> 00:21:42.050
them were left for getting roughly half of

00:21:42.050 --> 00:21:46.050
the questions. And here, with just one extra

00:21:46.050 --> 00:21:48.210
round of practice, that extra slightly less than

00:21:48.210 --> 00:21:50.635
a minute of extra practice, even this bottom

00:21:50.635 --> 00:21:53.515
quartile of readers performs quite well, almost as

00:21:53.515 --> 00:21:59.275
well as the overall population. So this is

00:21:59.275 --> 00:22:02.475
the power of practice efficient practice, at least.

00:22:03.250 --> 00:22:06.290
And this mechanism is useful for more than

00:22:06.290 --> 00:22:09.730
just quantum computing. In my personal practice, I

00:22:09.730 --> 00:22:12.850
have accumulated thousands and thousands of questions. I

00:22:12.850 --> 00:22:16.050
write questions about scientific papers, about conversations, about

00:22:16.050 --> 00:22:19.315
lectures, about memorable meals. I will definitely be

00:22:19.315 --> 00:22:20.915
writing a bunch about meetings I've had here

00:22:20.915 --> 00:22:23.955
today. All of this makes my daily life

00:22:23.955 --> 00:22:26.995
more rewarding because I know that if I

00:22:26.995 --> 00:22:29.715
invest my intention in something, I will internalize

00:22:29.715 --> 00:22:33.320
it indefinitely. Central to this is the idea

00:22:33.320 --> 00:22:36.920
of a daily ritual, a vessel for practice.

00:22:37.320 --> 00:22:40.840
Like meditation or exercise, I spend about ten

00:22:40.840 --> 00:22:44.055
minutes a day using this memory system. And

00:22:44.055 --> 00:22:47.015
because these exponential schedules are very efficient, those

00:22:47.015 --> 00:22:49.575
ten minutes are enough to maintain my memory

00:22:49.575 --> 00:22:52.135
for thousands of these questions and to allow

00:22:52.135 --> 00:22:54.135
me to add about 40 new questions every

00:22:54.135 --> 00:22:58.730
day. But there are some problems. So I

00:22:58.730 --> 00:23:00.250
want to mention a few of these problems.

00:23:00.650 --> 00:23:04.490
One is pattern matching. Once a question comes

00:23:04.490 --> 00:23:07.290
up a few times, I may recognize the

00:23:07.290 --> 00:23:09.610
text of the question without really thinking about

00:23:09.610 --> 00:23:12.565
its meaning. This creates the unpleasant feeling of

00:23:12.565 --> 00:23:15.765
parroting. But more importantly, I suspect it often

00:23:15.765 --> 00:23:18.725
leaves my memory brittle. I'll remember the answer,

00:23:18.885 --> 00:23:21.365
but only when queued exactly as I've practiced

00:23:21.365 --> 00:23:24.405
it. I wish the questions had more variability.

00:23:25.570 --> 00:23:29.810
Likewise, the questions are necessarily somewhat abstract. When

00:23:29.810 --> 00:23:32.370
I face a real problem in this domain,

00:23:32.370 --> 00:23:35.090
I won't always recognize what knowledge I should

00:23:35.090 --> 00:23:36.850
use or how to adapt it to that

00:23:36.850 --> 00:23:39.995
medium. A cognitive scientist would say maybe that

00:23:39.995 --> 00:23:43.595
I need to acquire schemas. Now, unless I

00:23:43.595 --> 00:23:47.035
intervene, these questions stay the same over years.

00:23:47.435 --> 00:23:49.835
They're maintaining my memory, but ideally they would

00:23:49.835 --> 00:23:52.955
push for further processing, increasing depth over time.

00:23:54.690 --> 00:23:57.730
And finally, returning to this talk's thesis, memory

00:23:57.730 --> 00:24:00.690
systems are too often disconnected from my authentic

00:24:00.690 --> 00:24:03.890
practice, what I'm actually interested in. Say I'm

00:24:03.890 --> 00:24:05.890
studying a topic in signal processing for a

00:24:05.890 --> 00:24:10.465
creative project. Unless I'm very careful, the questions

00:24:10.465 --> 00:24:12.305
that I get from that probably won't feel

00:24:12.305 --> 00:24:14.865
very connected to my project. They will probably

00:24:14.865 --> 00:24:18.385
feel like generic textbook questions about signal processing.

00:24:20.385 --> 00:24:23.000
Let's return to SAM now and see if

00:24:23.000 --> 00:24:24.520
we can apply some of these ideas about

00:24:24.520 --> 00:24:28.280
practice and memory. So Sam did the work

00:24:28.280 --> 00:24:30.520
to study that signal processing material. They want

00:24:30.520 --> 00:24:32.600
to make sure it actually sticks. How might

00:24:32.600 --> 00:24:35.720
that work? Let's say they can install a

00:24:35.720 --> 00:24:39.355
home screen widget, which ambiently exposes them to

00:24:39.355 --> 00:24:43.515
practice prompts drawn from highlights, questions asked, and

00:24:43.515 --> 00:24:45.915
any other activity that the AI can access.

00:24:46.795 --> 00:24:48.715
Sam can flip through these questions while waiting

00:24:48.715 --> 00:24:51.620
in line or on the bus. And notice

00:24:51.620 --> 00:24:54.260
that this isn't a generic textbook signal processing

00:24:54.260 --> 00:24:56.740
question. It's actually grounded in the details of

00:24:56.740 --> 00:24:59.540
Sam's brain computer interface project so that, at

00:24:59.540 --> 00:25:03.060
least aspirationally, practice feels somewhat more continuous with

00:25:03.060 --> 00:25:08.895
authentic doing. These synthesized prompts can vary each

00:25:08.895 --> 00:25:11.455
time they're asked so that Sam gets practice

00:25:13.055 --> 00:25:18.860
accessing the same idea from different angles. The

00:25:18.860 --> 00:25:22.540
prompts get deeper and more complex over time

00:25:22.780 --> 00:25:25.180
as Sam gets more confident with the material.

00:25:25.820 --> 00:25:29.180
Notice also that this question isn't so abstract.

00:25:29.580 --> 00:25:32.220
It's really about applying what Sam has learned

00:25:32.220 --> 00:25:34.405
in a bite sized form factor that can

00:25:34.405 --> 00:25:38.965
do anywhere. Now the widget can also include

00:25:38.965 --> 00:25:43.765
kind of more open ended discussion questions. Why

00:25:43.765 --> 00:25:45.605
do we think Metzger et al downsampled their

00:25:45.605 --> 00:25:51.140
signals to 200 Hertz? Maybe it's for performance?

00:25:52.820 --> 00:25:55.940
Here Sam gets some elaborative feedback and extra

00:25:55.940 --> 00:26:00.645
detail to consider in their answer. Now when

00:26:00.645 --> 00:26:02.645
questions are synthesized like this, it's important that

00:26:02.645 --> 00:26:06.885
Sam can steer them with feedback assuring that

00:26:06.885 --> 00:26:09.925
future questions are synthesized accordingly. Because again, what

00:26:09.925 --> 00:26:11.605
we're trying to do here is to make

00:26:11.605 --> 00:26:13.605
all of this not be homework, but to

00:26:13.605 --> 00:26:15.650
actually support what Sam is really trying to

00:26:15.650 --> 00:26:19.490
do. So far we've been looking at bite

00:26:19.490 --> 00:26:21.410
sized questions Sam can answer while they're out

00:26:21.410 --> 00:26:23.570
and about. But if they make time for

00:26:23.570 --> 00:26:26.130
a longer dedicated session, we can suggest meatier

00:26:26.130 --> 00:26:29.135
tasks like this one. And what's more, we

00:26:29.135 --> 00:26:31.375
can move that work out of fake practice

00:26:31.375 --> 00:26:34.495
land and into Sam's real context here at

00:26:34.495 --> 00:26:37.935
Jupyter Notebook. Notice that the task is still

00:26:37.935 --> 00:26:40.735
framed in terms of Sam's specific aims rather

00:26:40.735 --> 00:26:45.990
than some generic signal processing pipeline. Now, Sam

00:26:45.990 --> 00:26:48.550
got into this project not as a learning

00:26:48.550 --> 00:26:51.590
exercise, but as a way to start legitimately

00:26:51.590 --> 00:26:54.630
participating to start working with BCIs while playing

00:26:54.630 --> 00:26:58.025
to existing strengths. So just as our AI

00:26:58.025 --> 00:27:00.025
can help Sam find a tractable way into

00:27:00.025 --> 00:27:02.425
this space, it can also facilitate connections to

00:27:02.425 --> 00:27:05.625
communities of practice, here suggesting a local neurotech

00:27:05.625 --> 00:27:08.185
meetup. So let's say Sam goes to this

00:27:08.185 --> 00:27:10.905
meetup, meets a local scientist, and sets up

00:27:10.905 --> 00:27:14.560
a coffee date. With permission, Sam records the

00:27:14.560 --> 00:27:17.280
meeting, knowing the notes will probably be helpful

00:27:17.280 --> 00:27:19.680
later. And of course, Sam ends up surprised

00:27:19.680 --> 00:27:22.640
and intrigued quite a lot in this conversation.

00:27:24.320 --> 00:27:26.720
Our AI can notice these moments of surprise

00:27:27.425 --> 00:27:31.185
and help Sam metabolize them. Here, that insight

00:27:31.185 --> 00:27:37.185
turns into a reflective practice prompt. Four big

00:27:37.185 --> 00:27:40.650
design principles are threaded through Sam's story. I'd

00:27:40.650 --> 00:27:42.170
like to review them now, and for each,

00:27:42.170 --> 00:27:44.330
point out the ways that AI has helped

00:27:44.330 --> 00:27:49.370
me think about them. First, we bring guided

00:27:49.370 --> 00:27:52.810
learning to authentic contexts rather than thinking about

00:27:52.810 --> 00:27:55.355
it as a separate activity. We're able to

00:27:55.355 --> 00:27:57.435
make that happen by imagining an AI which

00:27:57.435 --> 00:28:00.395
can perceive and act across applications on Sam's

00:28:00.395 --> 00:28:03.275
computer. And as the audio transcript at the

00:28:03.275 --> 00:28:06.155
end of the story here alluded to, that

00:28:06.155 --> 00:28:08.715
action can potentially extend to activities outside of

00:28:08.715 --> 00:28:12.070
the computer as well. The AI can give

00:28:12.070 --> 00:28:15.430
appropriate guidance in part because, with permission and

00:28:15.430 --> 00:28:18.150
executing locally, it can learn from every piece

00:28:18.150 --> 00:28:20.870
of text that has ever crossed Sam's screen,

00:28:21.190 --> 00:28:23.270
every action they've ever taken on the computer.

00:28:24.835 --> 00:28:27.795
It can synthesize scaffolded dynamic media so that

00:28:27.795 --> 00:28:30.995
Sam can learn by doing, but with guidance.

00:28:32.915 --> 00:28:36.515
And then, when explicit learning activities are necessary,

00:28:36.915 --> 00:28:40.810
we suffuse them with authentic context. The AI

00:28:41.130 --> 00:28:43.290
in our story grounds all of the reading

00:28:43.290 --> 00:28:45.770
and practice Sam's doing in their actual aims.

00:28:46.490 --> 00:28:48.650
It helps Sam match the learning activities to

00:28:48.650 --> 00:28:51.690
their depth of interest. And it draws on

00:28:51.690 --> 00:28:54.650
important moments that happen while Sam is doing,

00:28:55.145 --> 00:28:56.985
like insights from that coffee meeting at the

00:28:56.985 --> 00:29:00.025
end or questions asked while implementing parts of

00:29:00.025 --> 00:29:02.985
the project. And it brings those moments into

00:29:02.985 --> 00:29:07.465
study activities. Besides connecting these two domains, we

00:29:07.465 --> 00:29:11.800
can also strengthen each of them. So our

00:29:11.800 --> 00:29:14.680
AI suggests tractable ways for Sam to just

00:29:14.680 --> 00:29:18.040
dive in to a new interest. And it

00:29:18.040 --> 00:29:20.360
helps Sam build connections with a community of

00:29:20.360 --> 00:29:23.845
practice. On the other side, when we are

00:29:23.845 --> 00:29:26.405
spending time in explicit learning activities, let's make

00:29:26.405 --> 00:29:29.765
sure that they actually work. So our AI

00:29:29.765 --> 00:29:33.845
creates a dynamic vessel for ongoing reinforcement. It

00:29:33.845 --> 00:29:36.030
varies what's in that vessel over time so

00:29:36.030 --> 00:29:38.990
that knowledge transfers more effectively to real situations.

00:29:39.790 --> 00:29:42.750
And it doesn't just maintain memory. It increases

00:29:42.750 --> 00:29:47.630
depth of understanding over time. Now I'd like

00:29:47.630 --> 00:29:51.575
to give two cheers for chatbot tutors. Most

00:29:51.575 --> 00:29:54.055
discussion of AI and education at the moment

00:29:54.055 --> 00:29:56.695
revolves around the framing of chatbot tutors. And

00:29:56.695 --> 00:29:59.335
I think this framing correctly identifies something really

00:29:59.335 --> 00:30:01.895
wonderful about language models, which is that they

00:30:01.895 --> 00:30:04.535
are so good at answering long tail questions

00:30:04.850 --> 00:30:06.930
if the user can articulate the question clearly

00:30:06.930 --> 00:30:09.090
enough. And if the user is trying to

00:30:09.090 --> 00:30:11.810
perform a routine task, chatbot tutors can often

00:30:11.810 --> 00:30:14.290
diagnose problems and find good ways to get

00:30:14.290 --> 00:30:17.585
the user unstuck. And that's great. But when

00:30:17.585 --> 00:30:20.145
I look at others' visions of chatbot tutors

00:30:20.145 --> 00:30:22.705
through the broader framing that we've been discussing,

00:30:23.345 --> 00:30:24.865
they're clearly missing a lot of what I

00:30:24.865 --> 00:30:28.305
want. I think these visions often fail to

00:30:28.305 --> 00:30:29.905
take seriously just how much a real tutor

00:30:29.905 --> 00:30:32.400
can really do. Large part, I think that's

00:30:32.400 --> 00:30:34.240
because the authors of these visions are usually

00:30:34.240 --> 00:30:38.160
thinking about educating, something they want to do

00:30:38.160 --> 00:30:41.680
to others rather than learning, something they want

00:30:41.680 --> 00:30:44.795
for themselves. Now a sad truth about the

00:30:44.795 --> 00:30:47.115
world is that postdocs and graduate students are

00:30:47.115 --> 00:30:50.475
incredibly underpaid. So it is actually surprisingly affordable

00:30:50.475 --> 00:30:51.915
to get an expert tutor for a technical

00:30:51.915 --> 00:30:55.355
topic I care about. But if I hire

00:30:55.355 --> 00:30:57.100
a real tutor as an adult to learn

00:30:57.100 --> 00:30:59.420
about signal processing, I will tell them about

00:30:59.420 --> 00:31:01.500
my interest in brain computer interfaces. And I

00:31:01.500 --> 00:31:04.060
will expect them to ground every conversation in

00:31:04.060 --> 00:31:06.460
that purpose. My goal here is not to

00:31:06.460 --> 00:31:09.500
learn signal processing. It is to participate in

00:31:09.500 --> 00:31:12.975
the creation of brain computer interfaces. Chatbot tutors

00:31:12.975 --> 00:31:14.975
are not interested in what I'm trying to

00:31:14.975 --> 00:31:17.375
do. There's a set of things they think

00:31:17.375 --> 00:31:19.855
I should know or should be able to

00:31:19.855 --> 00:31:22.335
do, and they view me as defective until

00:31:22.335 --> 00:31:25.790
I say the right things. If I hire

00:31:25.790 --> 00:31:27.550
a real tutor, I might ask them to

00:31:27.550 --> 00:31:28.990
sit beside me as I try to actually

00:31:28.990 --> 00:31:31.390
do something involving the material. They can see

00:31:31.390 --> 00:31:33.550
everything I'm doing, see what I'm pointing at.

00:31:33.710 --> 00:31:35.710
And if it's appropriate, I can scoot over

00:31:35.710 --> 00:31:38.315
and they can drive for a minute. By

00:31:38.315 --> 00:31:41.115
comparison, the typical conception of a chatbot tutor

00:31:41.275 --> 00:31:43.915
lives in a windowless box, and it can

00:31:43.915 --> 00:31:45.995
only see whatever's provided on scraps of paper

00:31:45.995 --> 00:31:48.395
passed under the door. It can have no

00:31:48.395 --> 00:31:52.480
effect on the outside world. My goal here

00:31:52.480 --> 00:31:55.040
is to dive in, to immerse myself, to

00:31:55.040 --> 00:31:58.160
start doing the thing. But these chatbot tutors

00:31:58.160 --> 00:32:00.880
can't join me where the action is. So

00:32:00.880 --> 00:32:03.120
interactions with them create distance and pull me

00:32:03.120 --> 00:32:06.385
away from immersion. If I hire a real

00:32:06.385 --> 00:32:10.545
tutor, we'll build a relationship. With every session,

00:32:10.545 --> 00:32:12.865
they'll learn more about me: my interests, my

00:32:12.865 --> 00:32:16.145
strengths, my confusions. Chatbot tutors, on the other

00:32:16.145 --> 00:32:21.100
hand, as typically conceived, are transactional, amnesiac. Now,

00:32:21.100 --> 00:32:22.860
we can fix that as context windows get

00:32:22.860 --> 00:32:26.700
longer. But that relationship is also important to

00:32:26.700 --> 00:32:30.540
my emotional connection. If I view conversation with

00:32:30.540 --> 00:32:33.605
my tutor as a kind of peripheral participation

00:32:33.605 --> 00:32:36.245
in the community I'm hoping to enter, an

00:32:36.245 --> 00:32:38.405
interaction between a novice in the discipline and

00:32:38.405 --> 00:32:41.285
an expert in the discipline, then tutoring just

00:32:41.285 --> 00:32:44.320
becomes part of doing the thing. But if

00:32:44.320 --> 00:32:46.960
my interaction with the tutor is transactional, that

00:32:46.960 --> 00:32:48.720
will tend to make my tutoring sessions feel

00:32:48.720 --> 00:32:52.720
like learning time, separate from doing the thing.

00:32:53.840 --> 00:32:56.080
Finally, people talk about how Aristotle was a

00:32:56.080 --> 00:32:59.285
tutor for Alexander the Great. But what's most

00:32:59.285 --> 00:33:01.765
valuable about having Aristotle as your tutor is

00:33:01.765 --> 00:33:04.885
not that he can diagnose misconceptions, but rather

00:33:04.885 --> 00:33:07.205
that he's modeling the practices and values of

00:33:07.205 --> 00:33:11.490
an earnest, intellectually engaged adult. He's demonstrating how

00:33:11.490 --> 00:33:13.650
and why he thinks about problems his taste

00:33:13.650 --> 00:33:16.530
and the discipline. The high growth periods that

00:33:16.530 --> 00:33:18.610
we love transform the way that we see

00:33:18.610 --> 00:33:24.695
the world. They reshape our identity. In my

00:33:24.695 --> 00:33:26.695
demo earlier, I showed a chatbot, but it

00:33:26.695 --> 00:33:28.615
didn't really work like most chatbot tutors I

00:33:28.615 --> 00:33:31.975
described. It focused all its actions on the

00:33:31.975 --> 00:33:35.255
user's interests rather than bringing its own agenda.

00:33:35.335 --> 00:33:37.495
It wasn't trapped in a little text box.

00:33:37.495 --> 00:33:40.230
It could see and take action in the

00:33:40.230 --> 00:33:43.110
context of authentic use. It can communicate through

00:33:43.110 --> 00:33:45.510
dynamic media. It had a deep memory drawing

00:33:45.510 --> 00:33:48.550
on everything I'd ever seen and written. So

00:33:48.550 --> 00:33:50.470
in some ways, the system I've shown is

00:33:50.470 --> 00:33:53.590
more like a real tutor. But in my

00:33:53.590 --> 00:33:56.375
ideal world, I don't want a tutor. I

00:33:56.375 --> 00:33:59.575
want to legitimately participate in some new discipline

00:33:59.575 --> 00:34:01.255
and learn what I need as much as

00:34:01.255 --> 00:34:04.935
possible from interaction with real practitioners. So I

00:34:04.935 --> 00:34:07.495
view the role of the augmented learning system

00:34:07.760 --> 00:34:10.800
as helping me act on my creative interests,

00:34:11.040 --> 00:34:12.800
ideally by letting me just dive in and

00:34:12.800 --> 00:34:16.160
start doing as much as possible. That will

00:34:16.160 --> 00:34:18.880
often mean scaffolding connections to and interactions with

00:34:18.880 --> 00:34:23.535
communities of practice. One theme for this Design

00:34:23.535 --> 00:34:26.495
at Large series is the ethics of AI

00:34:26.495 --> 00:34:29.375
and its likely enormous social impacts. So let

00:34:29.375 --> 00:34:31.135
me say, I am tremendously worried about those

00:34:31.135 --> 00:34:33.295
impacts in the general case. I am worried

00:34:33.295 --> 00:34:36.190
about despots locking in their powers. Lowering the

00:34:36.190 --> 00:34:40.030
bar to bioweapons, economic chaos. I would not

00:34:40.030 --> 00:34:43.550
feel comfortable ethically with researching more powerful frontier

00:34:43.550 --> 00:34:47.950
models myself. But within the narrower domain of

00:34:47.950 --> 00:34:50.595
learning that we've been discussing, my main moral

00:34:50.595 --> 00:34:52.835
concern is that we will end up trapped

00:34:52.835 --> 00:34:58.195
in a sad, narrow future. A condescending authoritarian

00:34:58.195 --> 00:35:00.835
frame dominates the narrative in the future of

00:35:00.835 --> 00:35:04.060
learning. I'll caricature it to make the point.

00:35:04.700 --> 00:35:07.100
With AI, we can finally take all of

00:35:07.100 --> 00:35:08.940
these defective kids that don't know the stuff

00:35:08.940 --> 00:35:11.020
they're supposed to know and get them to

00:35:11.020 --> 00:35:13.980
know it. You know, that's personalized learning. The

00:35:13.980 --> 00:35:16.300
AI lets us precisely identify where the kids

00:35:16.300 --> 00:35:18.985
are wrong or where they're ignorant and fix

00:35:18.985 --> 00:35:20.985
them. Then we can fill their heads to

00:35:20.985 --> 00:35:24.425
the brim with what's good for them. By

00:35:24.425 --> 00:35:27.225
contrast, the famous bicycle for the mind metaphor

00:35:27.385 --> 00:35:29.385
has no agenda other than the one that

00:35:29.385 --> 00:35:31.880
you bring. It just lets you reach a

00:35:31.880 --> 00:35:33.640
wider range of destinations than you could on

00:35:33.640 --> 00:35:35.560
foot, and it makes the journey more fun,

00:35:35.560 --> 00:35:37.640
maybe particularly if you're biking along with some

00:35:37.640 --> 00:35:40.280
friends. The bicycle asks, Where do you want

00:35:40.280 --> 00:35:44.120
to go? Of course, that question assumes your

00:35:44.120 --> 00:35:47.015
destination is well known and charted on some

00:35:47.015 --> 00:35:51.335
map. But those most rewarding, high growth experiences

00:35:51.655 --> 00:35:54.295
are often centered on a creative project. You're

00:35:54.295 --> 00:35:55.655
trying to get somewhere no one's ever gone

00:35:55.655 --> 00:35:58.375
before to reach the frontier and then starting

00:35:58.375 --> 00:36:01.990
charting links into the unknown. Learning in service

00:36:01.990 --> 00:36:06.070
of creation. It's a dynamic, context laden kind

00:36:06.070 --> 00:36:09.350
of learning. It's about more than just efficiency

00:36:09.350 --> 00:36:12.630
and correctness. More than just faster gears on

00:36:12.630 --> 00:36:15.125
a bike. And that's the kind of learning

00:36:15.125 --> 00:36:17.365
that I feel an almost moral imperative to

00:36:17.365 --> 00:36:28.870
help create. Thank you. I think we maybe

00:36:28.870 --> 00:36:30.790
have time for questions. We have some time

00:36:30.790 --> 00:36:39.190
for questions. Love to talk. Thank you. I

00:36:39.190 --> 00:36:40.630
really like a lot of what you said.

00:36:40.785 --> 00:36:42.545
One thing that I'm curious about is you

00:36:42.545 --> 00:36:46.065
mentioned that you add questions to your own,

00:36:46.945 --> 00:36:49.345
like for your space repetition routine, you add

00:36:49.345 --> 00:36:51.345
questions every And you said you add 40

00:36:51.345 --> 00:36:53.665
questions a day. So I guess what I'm

00:36:53.665 --> 00:36:56.230
wondering is, in your example you took one

00:36:56.230 --> 00:36:59.110
topic, but many people are often learning multiple

00:36:59.110 --> 00:37:01.430
things. And very often we don't know that

00:37:01.430 --> 00:37:03.830
we want to learn something until we've built

00:37:03.830 --> 00:37:06.950
some momentum. So my question is broadly, how

00:37:06.950 --> 00:37:08.550
do you decide what questions you want to

00:37:08.550 --> 00:37:11.885
add and how do you plan for your

00:37:11.885 --> 00:37:14.285
future self in some way? Right, right. First,

00:37:14.285 --> 00:37:16.605
should clarify. So I don't, in fact, add

00:37:16.605 --> 00:37:19.405
40 questions a day. That is the carrying

00:37:19.405 --> 00:37:23.325
capacity of my practice time. Ten minutes will

00:37:23.325 --> 00:37:26.050
support 40 a day added. In practice, it

00:37:26.050 --> 00:37:28.130
ends up like some kind of Poisson distribution

00:37:28.130 --> 00:37:31.330
or something. But how do I do this?

00:37:31.330 --> 00:37:33.890
How do I plan appropriately? You can't know

00:37:33.890 --> 00:37:35.970
what's going to be important to you in

00:37:35.970 --> 00:37:39.170
advance. Sometimes you can, but in general you

00:37:39.170 --> 00:37:42.095
can't. So the system needs to be resilient

00:37:42.095 --> 00:37:44.335
to that. The way that that works right

00:37:44.335 --> 00:37:47.615
now is very coarse. You can delete questions

00:37:47.615 --> 00:37:48.975
that you add if you decide that you

00:37:48.975 --> 00:37:51.295
don't like them. I view this as an

00:37:51.295 --> 00:37:53.615
interface problem of sorts. I think ideally you

00:37:53.615 --> 00:37:55.300
don't need to plan for what's going to

00:37:55.300 --> 00:37:57.620
be important. You can just do stuff, and

00:37:57.620 --> 00:38:00.020
stuff will get reinforced, and you can steer

00:38:00.020 --> 00:38:04.020
more of this, less of that. And I

00:38:04.020 --> 00:38:06.820
think that's an interesting challenge in interface design

00:38:06.820 --> 00:38:08.980
to create systems that behave more like that

00:38:08.655 --> 00:38:10.975
and less like these kind of discrete destructive

00:38:10.975 --> 00:38:15.775
actions destroy this question. Andy, I love that

00:38:15.775 --> 00:38:19.855
vision over here for that. Especially liked how

00:38:19.855 --> 00:38:22.975
you talked about how the AI could reinforce

00:38:23.130 --> 00:38:25.690
things you've learned and challenge you. It could

00:38:25.690 --> 00:38:29.130
integrate you with communities. Love all those ideas.

00:38:29.370 --> 00:38:30.970
What I didn't get, and maybe I guess

00:38:30.970 --> 00:38:33.450
I walked in two minutes late, was that

00:38:33.450 --> 00:38:36.970
an actual demo that you've created? No. Or

00:38:36.970 --> 00:38:38.810
is that just a vision for how you

00:38:38.810 --> 00:38:40.115
want it to be in the future? Yeah,

00:38:40.115 --> 00:38:42.435
I'm sorry for not making that clear. If

00:38:42.435 --> 00:38:44.275
it wasn't, I thought it looked sufficiently fake.

00:38:44.595 --> 00:38:47.795
No, this is concept art. Thank you for

00:38:47.795 --> 00:38:50.915
asking. There is, I suppose, a grand tradition

00:38:50.915 --> 00:38:53.235
in our discipline of smoke and mirror concept

00:38:53.235 --> 00:38:56.980
art. I have been using this talk as

00:38:56.980 --> 00:38:58.900
an excuse to figure out what I think

00:38:58.900 --> 00:39:02.420
I want to do with respect to AI

00:39:02.420 --> 00:39:05.860
and learning. And so these drawings are part

00:39:05.860 --> 00:39:11.975
of that process. I was curious, I wanted

00:39:11.975 --> 00:39:15.975
to follow-up on the question about sometimes I

00:39:15.975 --> 00:39:18.055
don't know what I want. And I think

00:39:18.055 --> 00:39:19.815
if you look at some of the more

00:39:20.135 --> 00:39:26.010
Montessori or Papert esque learning experiences, when you

00:39:26.090 --> 00:39:28.810
know when you have like, you know, if

00:39:28.810 --> 00:39:30.410
you just said school is gonna be whatever

00:39:30.410 --> 00:39:33.130
you're interested in forever. Yeah. It has lots

00:39:33.130 --> 00:39:38.985
of benefits. A challenge is that there are

00:39:38.985 --> 00:39:41.625
topics that I might benefit from, and I

00:39:41.625 --> 00:39:45.065
loved your paternalistic caricature as being that's what

00:39:45.065 --> 00:39:49.110
we don't want. There is a, like, the

00:39:49.110 --> 00:39:53.190
psychologist Dan Gilbert defines the happiness challenge as

00:39:53.190 --> 00:39:56.310
the delta between our current self and what

00:39:56.310 --> 00:39:58.390
our future self would have wanted us to

00:39:58.390 --> 00:40:01.670
do. I can, like a nice thing about

00:40:01.670 --> 00:40:05.175
a good tutor, your talk for example, is

00:40:05.175 --> 00:40:07.415
I'm learning things that will be valuable to

00:40:07.415 --> 00:40:09.735
me in the future that at 04:00 today

00:40:09.735 --> 00:40:12.535
I wouldn't have thought to ask for. Right.

00:40:13.175 --> 00:40:14.775
Yeah, yeah, I think this is totally right.

00:40:14.910 --> 00:40:16.510
I think the way that I think about

00:40:16.510 --> 00:40:18.670
this is a kind of unbundling. Normally when

00:40:18.670 --> 00:40:20.670
we think about schooling, we ask schooling to

00:40:20.670 --> 00:40:22.750
do two jobs: one, to decide what is

00:40:22.750 --> 00:40:24.270
it that I should know and then two,

00:40:24.270 --> 00:40:26.910
to cause me to know it. I think

00:40:26.910 --> 00:40:29.375
there are all kinds of cultural institutions that

00:40:29.375 --> 00:40:30.575
help us figure out what is it that

00:40:30.575 --> 00:40:33.135
we want to know. In the example that

00:40:33.135 --> 00:40:34.975
I showed, Sam figures out that they may

00:40:34.975 --> 00:40:37.695
be interested in brain computer interfaces through Twitter.

00:40:38.495 --> 00:40:40.335
If you are in San Diego, you can

00:40:40.335 --> 00:40:43.010
decide to attend this talk. Ideally, it doesn't

00:40:43.010 --> 00:40:44.370
feel like schooling. Hope it doesn't feel like

00:40:44.370 --> 00:40:46.210
schooling. And you can decide, oh, maybe I'm

00:40:46.210 --> 00:40:47.970
interested in studying some of the cognitive science

00:40:47.970 --> 00:40:50.530
that Andy mentioned. So I think there's a

00:40:50.530 --> 00:40:53.890
variety of cultural institutions and venues and channels

00:40:53.890 --> 00:40:56.690
we can use to help deliver that first

00:40:56.690 --> 00:41:01.735
part, and then possibly use separate tools for

00:41:01.735 --> 00:41:07.895
the other part. Good afternoon. Should we be

00:41:07.895 --> 00:41:10.215
planning for the day where we won't have

00:41:10.215 --> 00:41:14.990
to work due to artificial intelligence, automation, computers

00:41:14.990 --> 00:41:18.910
and robotics? Your thoughts. Thank you. I'm so

00:41:18.910 --> 00:41:20.590
grateful that you asked that question because I

00:41:20.590 --> 00:41:23.950
spent a month preparing for this talk, writing

00:41:23.950 --> 00:41:26.270
another version of this talk that I didn't

00:41:26.270 --> 00:41:28.625
give that was called What's Worth Learning in

00:41:28.625 --> 00:41:31.425
the Age of Strong AI? And it didn't

00:41:31.425 --> 00:41:32.945
end up aligning, so I didn't end up

00:41:32.945 --> 00:41:35.665
getting to present any of it. I'll give

00:41:35.665 --> 00:41:40.340
you a piece of that. Say that you

00:41:40.340 --> 00:41:45.380
are a composer, and you have some very

00:41:45.380 --> 00:41:47.700
vague idea about a new cello concerto that

00:41:47.700 --> 00:41:50.900
you would like to write. I claim that

00:41:50.900 --> 00:41:52.500
you can't just ask the AI to write

00:41:52.500 --> 00:41:55.515
it for you, because you don't know what

00:41:55.515 --> 00:41:57.675
it is that you want. In fact, you

00:41:57.675 --> 00:41:59.195
discover what the cello concerto is supposed to

00:41:59.195 --> 00:42:02.635
be through the process of composing it. Likewise,

00:42:02.635 --> 00:42:06.315
when we talk about software. An interesting thing

00:42:06.315 --> 00:42:09.260
about software is that it feels so messy

00:42:09.260 --> 00:42:10.860
and unpleasant so much of the time. We

00:42:10.860 --> 00:42:12.860
want a particular piece of software. We ask

00:42:12.860 --> 00:42:14.220
some people to go start making it for

00:42:14.220 --> 00:42:16.700
us. And then they come back 3x over

00:42:16.700 --> 00:42:20.060
time, 3x over budget, one third x quality.

00:42:20.060 --> 00:42:21.740
Why is software so hard? Why can't we

00:42:21.740 --> 00:42:25.475
just tell the system what we want and

00:42:25.555 --> 00:42:27.795
get the thing out the other side? And

00:42:27.795 --> 00:42:30.355
it turns out we actually do have that

00:42:30.355 --> 00:42:32.515
kind of technology. It's called formal modeling. We've

00:42:32.515 --> 00:42:34.275
had it for a long time. And I

00:42:34.275 --> 00:42:35.715
think the reason why it's not more widely

00:42:35.715 --> 00:42:37.610
used is that that's not how we think

00:42:37.610 --> 00:42:40.890
about designing software. Namely, we figure out what

00:42:40.890 --> 00:42:43.050
software we want in the process of making

00:42:43.050 --> 00:42:47.690
it. It's continuously negotiated. It's contingent. So I

00:42:47.690 --> 00:42:50.250
think there are many activities in human life

00:42:50.315 --> 00:42:52.715
that have that characteristic where we can't actually

00:42:52.715 --> 00:42:54.715
appropriately specify what it is that we want

00:42:54.715 --> 00:42:56.315
to the model. We can't externalize it or

00:42:56.315 --> 00:42:58.635
make it legible. We have to participate in

00:42:58.635 --> 00:43:00.715
the creation of the thing. And then we

00:43:00.715 --> 00:43:02.075
can ask, what do we need to know

00:43:02.075 --> 00:43:03.755
in order to participate in that creation? What

00:43:03.755 --> 00:43:06.075
are the dynamics of that participation? How much

00:43:06.200 --> 00:43:09.560
injection of involvement is necessary to steer appropriately.

00:43:10.520 --> 00:43:12.520
And I have some thoughts on that, but

00:43:12.520 --> 00:43:13.960
I should probably move on to the next

00:43:13.960 --> 00:43:16.840
question. So yes, I hope that's somewhat helpful.

00:43:17.880 --> 00:43:23.785
Yeah. Hi. So with my question, I was

00:43:23.785 --> 00:43:25.785
thinking about how with the AI, what you

00:43:25.785 --> 00:43:28.505
have is you like say that AI advancement

00:43:28.505 --> 00:43:30.505
will lead to some dystopian feature where we

00:43:30.505 --> 00:43:32.185
find people the knowledge and then we force

00:43:32.185 --> 00:43:34.220
them to know it. But who's to say

00:43:34.220 --> 00:43:35.820
that that is still already happening to some

00:43:35.820 --> 00:43:39.900
extent with curriculum right now without AI? Isn't

00:43:39.900 --> 00:43:41.820
necessarily a concern as much as other things,

00:43:41.820 --> 00:43:43.740
I think. But beyond that, I think it's

00:43:43.740 --> 00:43:46.540
kind of like, because that problem can happen,

00:43:46.540 --> 00:43:48.115
like when we don't look at the root

00:43:48.115 --> 00:43:50.435
problem, it can happen in the most immersive

00:43:50.435 --> 00:43:53.155
learning. In ethnic studies class, you can still

00:43:53.155 --> 00:43:55.715
end up restricting someone to that specific topic

00:43:55.715 --> 00:43:57.635
instead of connecting identity as much as you

00:43:57.635 --> 00:43:59.235
would in say a math class or something

00:43:59.235 --> 00:44:01.900
like that. So what if you could implement

00:44:01.900 --> 00:44:05.180
that like sort of, I guess to give

00:44:05.180 --> 00:44:07.580
another example of how in the other hand,

00:44:07.580 --> 00:44:09.820
you can do something really well, even in

00:44:09.820 --> 00:44:11.660
a math class, for example, if you look

00:44:11.660 --> 00:44:13.420
at the higher concepts or if someone explains

00:44:13.420 --> 00:44:15.345
it really well, or in like say neuroscience

00:44:15.345 --> 00:44:17.425
and those sorts of fields, there might be

00:44:17.425 --> 00:44:19.425
content that is above the cost that is

00:44:19.425 --> 00:44:21.585
interesting that would make someone more interested and

00:44:21.585 --> 00:44:24.145
able to learn the class themselves, especially if

00:44:24.145 --> 00:44:26.145
it connects to their own prior knowledge. So

00:44:26.450 --> 00:44:29.890
what would you think if like, guess, how

00:44:29.890 --> 00:44:31.410
do you think you would implement this into

00:44:31.410 --> 00:44:33.570
like a learning system to take advantage of

00:44:33.570 --> 00:44:35.250
it like say Canvas? Do you think that

00:44:35.250 --> 00:44:36.610
you could do it in a way that

00:44:36.610 --> 00:44:39.490
you could customize in part assignments to synthesize

00:44:39.490 --> 00:44:42.335
the students' interests and the teachers' intent to

00:44:42.335 --> 00:44:45.055
teach people necessary content and teach people the

00:44:45.055 --> 00:44:47.135
content that they want to know in a

00:44:47.135 --> 00:44:48.975
way that they might be doing more, but

00:44:48.975 --> 00:44:51.215
ultimately less because it's easier for them if

00:44:51.215 --> 00:44:53.135
they know the context and can connect to

00:44:53.135 --> 00:44:56.700
it. Cool. I think I followed. So to

00:44:56.700 --> 00:44:59.420
your first question, yeah, I think you're right.

00:45:00.860 --> 00:45:06.380
That part of the talk was part of

00:45:06.380 --> 00:45:10.905
a complaint about schooling in general. And AI

00:45:10.905 --> 00:45:13.785
doesn't necessarily make that worse, though it may

00:45:13.785 --> 00:45:17.465
continue trends I don't like. To your second

00:45:17.465 --> 00:45:21.465
point, or your second question, I have deliberately

00:45:21.465 --> 00:45:25.145
avoided the question of schooling in this talk.

00:45:27.040 --> 00:45:28.640
And I did that for a reason. I

00:45:28.640 --> 00:45:31.280
think it makes everything very complicated. So in

00:45:31.280 --> 00:45:37.360
terms of integrating into Canvas, I think it's

00:45:37.360 --> 00:45:40.835
a very difficult position to start. I have

00:45:40.835 --> 00:45:43.955
done a bunch of collaborations these past few

00:45:43.955 --> 00:45:49.235
years with professors in higher ed teaching large

00:45:49.235 --> 00:45:53.075
classes. And what I experience again and again

00:45:53.635 --> 00:45:56.600
is just an enormous fraction of the student

00:45:56.600 --> 00:45:59.480
body that is just fundamentally not engaged with

00:45:59.480 --> 00:46:02.520
the class. And I don't think any amount

00:46:02.520 --> 00:46:06.920
of UI chicanery or AI involvement is going

00:46:06.920 --> 00:46:10.285
to change that. And I think I basically

00:46:10.285 --> 00:46:11.965
don't want to put myself into that problem

00:46:11.965 --> 00:46:14.205
solving situation. In some sense, that's actually why

00:46:14.205 --> 00:46:19.325
I left Khan Academy. Hey, Andy. My name's

00:46:19.325 --> 00:46:21.165
Taylor. I'm a software engineer at Replit. So

00:46:21.325 --> 00:46:24.200
I would say, in some sense, my salary

00:46:24.200 --> 00:46:25.800
depends on some of the ideas in your

00:46:25.800 --> 00:46:27.720
talk, which is to say that AI can

00:46:27.720 --> 00:46:30.200
be an effective tool for teaching difficult concepts

00:46:30.200 --> 00:46:33.640
like computer programming. So my question to you

00:46:33.640 --> 00:46:38.265
is, have you seen any inklings of this

00:46:38.265 --> 00:46:41.465
being true, the ideas in your talk of

00:46:41.465 --> 00:46:45.145
the delta between something like a GBT, being

00:46:45.145 --> 00:46:47.545
a teacher, and what you're outlining? Have you

00:46:47.545 --> 00:46:50.825
seen any of those ideas actually start to

00:46:50.825 --> 00:46:52.340
play out? Or do you think this is

00:46:52.340 --> 00:46:54.740
purely speculative with what we have today? Yeah.

00:46:54.740 --> 00:46:58.500
I think we're seeing a lot of hints

00:46:58.500 --> 00:47:02.740
at what I described already. So lots of

00:47:02.740 --> 00:47:06.215
people already use GPT to just dive into

00:47:06.215 --> 00:47:10.375
stuff. It's missing that universal IO. It's missing

00:47:10.375 --> 00:47:14.055
the billion token context window. And yet it's

00:47:14.055 --> 00:47:18.060
still already able to deliver some value, which

00:47:18.060 --> 00:47:20.700
is great. I think missing also that the

00:47:20.700 --> 00:47:24.380
bridge to textbooks again and again, I've been

00:47:24.380 --> 00:47:26.460
talking to people not that textbooks are the

00:47:26.460 --> 00:47:28.620
answer. Here I'm using textbook as synecdoche for

00:47:28.620 --> 00:47:32.220
some kind of deeper, more focused learning experience.

00:47:32.785 --> 00:47:34.145
I talk to a lot of people who

00:47:34.145 --> 00:47:38.545
get a really good start with GPT because

00:47:38.545 --> 00:47:40.785
they can get the couple sentence answers, and

00:47:40.785 --> 00:47:42.225
that lets them make a certain amount of

00:47:42.225 --> 00:47:43.985
progress. And that's really motivating. You can kick

00:47:43.985 --> 00:47:46.385
up some momentum, and momentum is very powerful.

00:47:47.105 --> 00:47:49.720
But they hit a wall. And I had

00:47:49.720 --> 00:47:52.680
a section that I cut talking about programming.

00:47:52.680 --> 00:47:54.600
I think it's really interesting that in programming,

00:47:54.600 --> 00:47:57.240
a lot of people can manage to self

00:47:57.240 --> 00:47:59.800
teach programming. And in part, I think that's

00:47:59.800 --> 00:48:02.835
because of things like syntax, for instance, is

00:48:02.835 --> 00:48:05.475
reinforced every time you sit down to program.

00:48:06.595 --> 00:48:09.475
Obscure facets of syntax, which are not reinforced

00:48:09.475 --> 00:48:12.195
regularly, like maybe your macro library or whatever,

00:48:12.355 --> 00:48:17.870
people do tend to forget. But again and

00:48:17.870 --> 00:48:20.670
again you meet people who are like, I

00:48:20.670 --> 00:48:23.390
don't understand how pointers work though. That asterisk

00:48:23.390 --> 00:48:25.070
can see. It's like it's a bridge too

00:48:25.070 --> 00:48:27.070
far. So there's a certain amount of conceptual

00:48:27.070 --> 00:48:30.590
understanding that seems acquirable with the frontier of

00:48:30.590 --> 00:48:33.275
self learning tools that are widely available. And

00:48:33.275 --> 00:48:35.435
then as soon as you run into difficult

00:48:35.435 --> 00:48:38.315
conceptual territory, it's just a cliff. So I

00:48:38.315 --> 00:48:41.915
think we're seeing glimmers of progress in this

00:48:41.915 --> 00:48:44.795
vein, and perhaps this talk will inspire people

00:48:44.795 --> 00:48:51.160
to try some more stuff. Hello. Hi. So

00:48:51.160 --> 00:48:53.960
my question is, to what extent do you

00:48:53.960 --> 00:48:57.640
think the desire to learn comes from the

00:48:57.640 --> 00:49:00.280
innate pleasure of learning or specific to whatever

00:49:00.280 --> 00:49:02.325
material the person learning is? And to what

00:49:02.325 --> 00:49:04.405
extent do you think the desire to learn

00:49:04.405 --> 00:49:07.365
comes from some sort of use of the

00:49:07.365 --> 00:49:09.525
material the person learns? And do you think

00:49:12.325 --> 00:49:14.485
making this distinction is important to the design

00:49:14.485 --> 00:49:18.730
of systems for learning? Yeah, probably. This is

00:49:18.730 --> 00:49:21.210
a good question, and it's something that I

00:49:21.210 --> 00:49:25.050
don't emphasize perhaps quite clearly enough. In the

00:49:25.050 --> 00:49:28.810
example story that I gave, everything is motivated

00:49:28.810 --> 00:49:32.275
by this persona, Sam, wanting to do a

00:49:32.275 --> 00:49:33.955
project. It's very concrete. It's out in the

00:49:33.955 --> 00:49:39.235
world. That doesn't mean that curiosity based learning

00:49:39.555 --> 00:49:41.555
is any less legitimate or that I think

00:49:41.555 --> 00:49:43.475
any of the claims don't apply. It's just

00:49:43.475 --> 00:49:46.970
that what authentic practice and legitimate participation looks

00:49:46.970 --> 00:49:50.330
like is different. So in mathematics, for instance,

00:49:50.330 --> 00:49:51.690
which may be very abstract, it may not

00:49:51.690 --> 00:49:53.210
be like a project I'm trying to do

00:49:53.210 --> 00:49:55.530
as I learn about algebraic topology or something

00:49:55.530 --> 00:49:58.785
like that, What legitimate practice looks like is

00:49:58.785 --> 00:50:03.105
engaging with problems and questions in algebraic topology

00:50:03.105 --> 00:50:08.145
that I find authentically interesting. And as soon

00:50:08.145 --> 00:50:09.905
as you make that move, rather than thinking

00:50:09.905 --> 00:50:11.720
about, well, I need to learn algebraic topology

00:50:11.720 --> 00:50:13.560
in order to do this four d renderer

00:50:13.560 --> 00:50:14.840
that I was working on for a game

00:50:14.840 --> 00:50:17.000
project, if you think about it from the

00:50:17.000 --> 00:50:19.640
perspective of authentic curiosity, then I think much

00:50:19.640 --> 00:50:24.765
of what I'm saying applies. However, there are

00:50:24.765 --> 00:50:28.765
issues with rendering legible the nature of the

00:50:28.765 --> 00:50:32.205
curiosity and the interest to the AI. A

00:50:32.205 --> 00:50:34.605
lot of what's happening is internal, and that

00:50:34.605 --> 00:50:35.805
may make a lot of what I'm describing

00:50:35.805 --> 00:50:40.640
somewhat more difficult. The nature of relation to

00:50:40.640 --> 00:50:44.080
community of practices changes somewhat, although not completely.

00:50:44.560 --> 00:50:48.240
So it's a partial answer, I suppose. Is

00:50:48.240 --> 00:50:50.640
there someone with the microphone? Hi, Jonathan. Hi,

00:50:50.640 --> 00:50:55.125
Andy. This is great. Love the deepness of

00:50:55.125 --> 00:50:58.165
the reflective practice you're demonstrating for us I

00:51:00.245 --> 00:51:03.045
think, is it Aristotle that said, give me

00:51:03.045 --> 00:51:04.965
a child till the age of seven and

00:51:04.965 --> 00:51:07.860
I'll show you the man? And when you

00:51:07.860 --> 00:51:10.020
bring up the ethical issues, this is what

00:51:10.020 --> 00:51:13.380
scares me the most is for an AI

00:51:13.380 --> 00:51:23.255
tutor. Have you thought about adversarial tutoring? Given

00:51:23.255 --> 00:51:25.095
that we're going to have, if we do,

00:51:25.095 --> 00:51:27.735
if we hypothesize AI tutors are out there

00:51:27.735 --> 00:51:30.695
and that we have the schooling industrial complex

00:51:30.855 --> 00:51:35.730
producing them, how do we counteract them? I

00:51:35.730 --> 00:51:40.130
love that. It's like manufacturing the mythical and

00:51:40.130 --> 00:51:43.090
often in the teaching community maligned Robin Williams

00:51:43.730 --> 00:51:47.570
character, the teacher film whose name I'm forgetting.

00:51:49.675 --> 00:51:51.755
I haven't thought about that. It's a lovely

00:51:52.075 --> 00:51:58.955
provocation. I feel uncomfortable with an activist framing,

00:51:58.955 --> 00:52:00.475
where it's like, I need to get out

00:52:00.475 --> 00:52:02.880
there because I know what's best for the

00:52:02.880 --> 00:52:05.040
people or for the kids. They're doing it

00:52:05.040 --> 00:52:06.640
wrong. I'm going make a thing that's going

00:52:06.640 --> 00:52:09.120
to put fluoride in the drinking water so

00:52:09.120 --> 00:52:12.160
that they end up in the right spot.

00:52:12.160 --> 00:52:17.785
I'm uncomfortable with that. I feel much more

00:52:17.785 --> 00:52:19.705
comfortable saying, well, I can make a thing

00:52:19.705 --> 00:52:20.985
that lets you pursue the things you're interested

00:52:20.985 --> 00:52:23.865
in, if you would like that. That feels

00:52:24.105 --> 00:52:27.145
less complicated. So I will need to think

00:52:27.145 --> 00:52:29.385
about your question. Find it very provocative. Thank

00:52:29.385 --> 00:52:36.300
you. Hey, Andy. I have a question for

00:52:36.300 --> 00:52:41.180
you about this idea of that AI tutor.

00:52:41.260 --> 00:52:44.835
I'm wondering, is there a limit to what

00:52:44.835 --> 00:52:47.075
kind of disciplines that that course kind of

00:52:47.075 --> 00:52:49.875
technology could be applied to? I've always deemed

00:52:49.875 --> 00:52:53.155
myself as being book smarts but not street

00:52:53.155 --> 00:52:57.315
smarts. That's a great question. One of the

00:52:57.315 --> 00:53:01.350
inspirations for this talk was trying to exorcise

00:53:01.350 --> 00:53:05.350
myself of the young ladies illustrated primer. I

00:53:05.350 --> 00:53:06.790
don't know if that phrase means anything to

00:53:06.790 --> 00:53:09.910
you. Ah, that's a shame. Okay, so an

00:53:09.910 --> 00:53:13.255
inspiration for many educational technologists is this book

00:53:13.255 --> 00:53:15.495
called The Diamond Age by Neal Stephenson, which

00:53:15.495 --> 00:53:19.175
depicts a sort of far future utopian learning

00:53:19.175 --> 00:53:23.655
environment. It's like a magical book that transforms

00:53:23.655 --> 00:53:26.030
a young girl's life. And one of the

00:53:26.030 --> 00:53:27.950
things that's interesting about this book that I

00:53:27.950 --> 00:53:29.550
think is underappreciated is that it is almost

00:53:29.550 --> 00:53:32.270
exclusively focused on street smarts. So this book

00:53:32.270 --> 00:53:34.510
teaches her martial arts and getting out of

00:53:34.510 --> 00:53:36.910
sticky situations and persuading people and so on.

00:53:38.805 --> 00:53:41.605
And I chose not to deal with any

00:53:41.605 --> 00:53:45.685
of that. I think the way that I

00:53:45.685 --> 00:53:50.165
would handle much of that looks very different.

00:53:51.240 --> 00:53:53.960
And I'm afraid I haven't really thought about

00:53:53.960 --> 00:53:58.280
how I would handle that. It's difficult to

00:53:58.280 --> 00:54:02.440
think about authentic practice of street smarts. Like

00:54:02.440 --> 00:54:04.920
what does that look like? Is it like

00:54:05.235 --> 00:54:07.555
I'm going to go to a bad neighborhood

00:54:07.555 --> 00:54:10.195
and like look purposeful as I walk? And

00:54:10.195 --> 00:54:13.075
then but that's not exactly authentic practice because

00:54:13.075 --> 00:54:14.435
like you went to this neighborhood just for

00:54:14.435 --> 00:54:17.795
that purpose. So I find myself confused thinking

00:54:17.795 --> 00:54:22.790
about this. And I find myself most comfortable

00:54:22.870 --> 00:54:26.950
when I think about people who enjoy practicing

00:54:26.950 --> 00:54:30.230
martial arts not as a kind of preparatory

00:54:30.230 --> 00:54:35.915
measure for imagined conflict in the future, but

00:54:35.915 --> 00:54:37.595
rather because they like the way it makes

00:54:37.595 --> 00:54:39.595
their body feel. They like their community at

00:54:39.595 --> 00:54:43.355
the dojo. And so if we start thinking

00:54:43.355 --> 00:54:46.130
about that, like, oh, it would be fun

00:54:46.130 --> 00:54:49.490
to do some exercise with others, then I

00:54:49.490 --> 00:54:51.250
think some of the same techniques can help.

00:54:51.250 --> 00:54:53.810
So you can probably use tools to help

00:54:53.810 --> 00:54:56.850
you find an appropriate community and perhaps to

00:54:56.850 --> 00:54:59.090
help you practice appropriately. I play the piano.

00:54:59.775 --> 00:55:02.575
And that's not exactly book smart, but one

00:55:02.575 --> 00:55:05.855
can use practice systems, vessels for practice like

00:55:05.855 --> 00:55:09.695
I've described, to orchestrate piano practice. You can

00:55:09.695 --> 00:55:11.775
imagine extending that to martial arts. I don't

00:55:11.775 --> 00:55:13.935
know about other kinds of street smarts, but

00:55:13.935 --> 00:55:17.420
perhaps. Thanks for the question. Let's thank Andy,

00:55:17.420 --> 00:55:18.940
and I'm sure he'll stay around a few

00:55:18.940 --> 00:55:23.980
little. Thanks everybody. Appreciate you.
