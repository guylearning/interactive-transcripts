WEBVTT

NOTE
Transcription provided by Deepgram
Request Id: 9414536c-210a-4750-9e95-b29b65a132f7
Created: 2025-05-15T13:21:01.087Z
Duration: 3328.6792
Channels: 1

00:00:02.640 --> 00:00:06.640
Talks about learning technology often center on technology.

00:00:07.280 --> 00:00:09.280
So instead, I'd like to begin by asking:

00:00:09.840 --> 00:00:13.840
What do you want learning to be like

00:00:12.665 --> 00:00:15.545
for yourself? If you could just snap your

00:00:15.545 --> 00:00:19.465
fingers and have the ideal perfect learning environment,

00:00:19.785 --> 00:00:23.865
what would that be like? One way to

00:00:23.865 --> 00:00:26.265
start getting at this question is to ask,

00:00:27.190 --> 00:00:31.910
what were the most rewarding high growth periods

00:00:31.910 --> 00:00:35.910
of your life? I've noticed two patterns when

00:00:35.910 --> 00:00:39.605
I ask people this question. First, people will

00:00:39.605 --> 00:00:41.205
tell me about a period in their life

00:00:41.205 --> 00:00:44.565
where they learned a ton, but where learning

00:00:44.565 --> 00:00:48.085
wasn't the point. Instead, they were totally immersed

00:00:48.085 --> 00:00:49.845
in some project with a great deal of

00:00:49.845 --> 00:00:52.885
personal meaning, like a scrappy startup or a

00:00:52.885 --> 00:00:56.260
research project or an artistic urge or just

00:00:56.260 --> 00:01:00.420
a fiery curiosity. And a lot of learning

00:01:00.420 --> 00:01:02.820
happened just along the way. They learned whatever

00:01:02.820 --> 00:01:04.740
they needed. They dove in. They got their

00:01:04.740 --> 00:01:09.915
hands dirty. Secondly, in these stories, learning really

00:01:10.075 --> 00:01:15.675
worked. People emerged feeling transformed, newly capable, filled

00:01:15.675 --> 00:01:17.915
with insights that remained with them years later.

00:01:19.570 --> 00:01:21.650
These stories are so vivid in part because

00:01:21.650 --> 00:01:26.210
learning rarely feels this way. People are often

00:01:26.210 --> 00:01:28.210
telling me somewhat wistfully about an experience that

00:01:28.210 --> 00:01:31.170
occurred years or decades earlier. Learning rarely feels

00:01:31.170 --> 00:01:34.265
so subordinated to an authentic pursuit. Often if

00:01:34.265 --> 00:01:36.345
we try to just dive in, we dive

00:01:36.345 --> 00:01:38.425
into a brick wall, or we find ourselves

00:01:38.425 --> 00:01:41.465
uneasily cargo culting others without any real understanding

00:01:41.465 --> 00:01:44.745
of what's actually going on. So why can't

00:01:44.745 --> 00:01:48.080
we just dive in all the time? Instead,

00:01:48.080 --> 00:01:49.600
it often feels like we have to put

00:01:49.600 --> 00:01:51.680
our aims on hold while we go do

00:01:51.680 --> 00:01:55.840
some homework and learn properly. And worse, learning

00:01:55.840 --> 00:01:59.280
so often just doesn't really work. We take

00:01:59.280 --> 00:02:02.095
the class, we read the book, And then

00:02:02.095 --> 00:02:03.295
when we try to put that knowledge into

00:02:03.295 --> 00:02:06.575
practice, we find that it's fragile. It doesn't

00:02:06.575 --> 00:02:10.255
transfer well. Worse, we'll often find that we've

00:02:10.255 --> 00:02:11.695
forgotten half of it by the time we

00:02:11.695 --> 00:02:14.255
try to use it. Why does learning so

00:02:14.255 --> 00:02:19.080
often fail to actually work? These questions connect

00:02:19.080 --> 00:02:21.080
to an age old conflict among educators and

00:02:21.080 --> 00:02:24.280
learning scientists between implicit learning, also known as

00:02:24.280 --> 00:02:28.040
discovery learning, inquiry learning, situated learning, and guided

00:02:28.040 --> 00:02:30.760
learning, which is often represented by cognitive scientists

00:02:30.760 --> 00:02:32.600
of the kind we find here at UCSD.

00:02:33.695 --> 00:02:35.855
Advocates of implicit learning methods argue that we

00:02:35.855 --> 00:02:40.175
should prioritize discovery, motivation, authentic involvement, and being

00:02:40.175 --> 00:02:43.135
situated in a community of practice. In the

00:02:43.135 --> 00:02:46.175
opposing camp, cognitive psychologists argue that you really

00:02:46.175 --> 00:02:47.855
do need to pay attention to the architecture

00:02:47.855 --> 00:02:50.360
of cognition, to long term memory, to procedural

00:02:50.360 --> 00:02:53.800
fluency, and to scaffold appropriately for cognitive load.

00:02:54.760 --> 00:02:57.640
In my view, each of these of view

00:02:58.120 --> 00:03:03.195
contains a lot of truth. And they also

00:03:03.195 --> 00:03:07.195
ignore each other to their detriment. Implicit learning

00:03:07.195 --> 00:03:10.875
aptly recognizes meaning and emotion but ignores the

00:03:10.875 --> 00:03:13.515
often decisive constraints of cognition what we need

00:03:13.515 --> 00:03:17.290
to actually make learning work. Guided learning advocates

00:03:17.290 --> 00:03:19.930
are focused on making learning work, and they

00:03:19.930 --> 00:03:23.450
sometimes succeed, but usually by sacrificing that purposeful

00:03:23.450 --> 00:03:25.690
sense of immersion that we love about those

00:03:25.690 --> 00:03:29.835
rewarding high growth periods. One obvious approach is

00:03:29.835 --> 00:03:32.715
to try compromise. Project based learning is a

00:03:32.715 --> 00:03:35.435
good representation of that. By creating a scaffolded

00:03:35.435 --> 00:03:37.595
series of projects, the suggestion is that we

00:03:37.595 --> 00:03:39.275
can get some of the benefits of implicit

00:03:39.275 --> 00:03:44.620
learning authenticity, motivation, transferability while also getting the

00:03:44.620 --> 00:03:47.500
instructional control and the cognitive awareness that might

00:03:47.500 --> 00:03:52.860
be typical of traditional courses. The trouble is

00:03:52.860 --> 00:03:54.620
that usually we get the worst of both

00:03:54.620 --> 00:03:57.915
worlds. I remember when I was in college,

00:03:57.915 --> 00:03:59.755
I was interested in three d game programming,

00:03:59.755 --> 00:04:01.275
so I signed up for a project based

00:04:01.275 --> 00:04:04.635
course on computer graphics. The trouble was that

00:04:04.635 --> 00:04:07.675
those projects weren't my projects. So a few

00:04:07.675 --> 00:04:10.260
weeks in, I ended up implementing array marching

00:04:10.260 --> 00:04:13.060
for more efficient bump mapping. And unfortunately, I

00:04:13.060 --> 00:04:15.220
was really just implementing some math that I

00:04:15.220 --> 00:04:16.660
was handed because this course was trying to

00:04:16.660 --> 00:04:18.500
take project based learning seriously. So there weren't

00:04:18.500 --> 00:04:21.700
long textbook readings, weren't long problem sets. But

00:04:21.700 --> 00:04:24.055
I didn't understand the math. What What I

00:04:24.055 --> 00:04:25.335
ended up with was a project that I

00:04:25.335 --> 00:04:27.655
didn't care about implementing something I didn't understand.

00:04:29.175 --> 00:04:31.975
Instead, I suggest, we should take both views

00:04:31.975 --> 00:04:34.935
seriously. Find a way to synthesize the two.

00:04:35.495 --> 00:04:38.055
You really do want to make doing the

00:04:38.055 --> 00:04:41.720
thing the primary activity. But the realities of

00:04:41.720 --> 00:04:44.520
cognitive psychology mean that in many cases, you

00:04:44.520 --> 00:04:48.120
really do need explicit guidance, scaffolding, practice, intention

00:04:48.120 --> 00:04:52.280
and memory support. Learning by immersion works naturalistically

00:04:52.215 --> 00:04:53.975
when the material has a low enough complexity

00:04:53.975 --> 00:04:55.895
relative to your prior knowledge that you can

00:04:55.895 --> 00:04:57.975
successfully process it on the fly and when

00:04:57.975 --> 00:05:02.695
natural participation routinely reinforces everything important, giving you

00:05:02.695 --> 00:05:05.970
fluency. When those conditions aren't satisfied, which is

00:05:05.970 --> 00:05:07.410
most of the time, you will need some

00:05:07.410 --> 00:05:10.530
support. You want to just dive in. And

00:05:10.530 --> 00:05:13.650
you want learning to actually work. To make

00:05:13.650 --> 00:05:15.650
that happen, we need to infuse your authentic

00:05:15.650 --> 00:05:19.115
projects with guided support, where necessary, inspired by

00:05:19.115 --> 00:05:21.515
the best ideas from cognitive science. And if

00:05:21.515 --> 00:05:24.875
there's something that requires more focused, explicit learning,

00:05:25.115 --> 00:05:27.275
then you want those experiences to be utterly

00:05:27.275 --> 00:05:32.060
in service to your actual aims. Now I've

00:05:32.060 --> 00:05:33.980
been thinking about this synthesis for many years,

00:05:33.980 --> 00:05:37.740
and honestly, I've mostly been pretty stuck. Recently

00:05:37.740 --> 00:05:39.900
though, I've been thinking a lot about AI,

00:05:40.540 --> 00:05:43.100
which I know gets an eye roll. Certainly

00:05:44.245 --> 00:05:47.285
every mention of AI in education gets an

00:05:47.285 --> 00:05:50.165
eye roll from me. But I confess, the

00:05:50.165 --> 00:05:53.205
possibility of AI has helped me finally get

00:05:53.205 --> 00:05:55.765
what feels like some traction on this particular

00:05:55.765 --> 00:05:58.085
problem. So I'd like to share some of

00:05:58.085 --> 00:06:01.540
those early concepts today. We'll explore this possible

00:06:01.540 --> 00:06:05.060
synthesis through a story in six parts. Meet

00:06:05.060 --> 00:06:08.660
Sam. Sam studied computer science in university, and

00:06:08.660 --> 00:06:10.420
they're now working as a software engineer at

00:06:10.420 --> 00:06:14.655
a big tech company. But Sam is bored

00:06:14.975 --> 00:06:17.935
at their day job. Not everything is boring,

00:06:17.935 --> 00:06:20.015
though. Every time Sam sees a tweet announcing

00:06:20.015 --> 00:06:22.415
new results in brain computer interfaces, they're absolutely

00:06:22.415 --> 00:06:25.375
captivated. These projects seem so much more interesting

00:06:25.375 --> 00:06:28.050
than what they're doing by day. Sam pulls

00:06:28.050 --> 00:06:30.370
up the papers looking for some way to

00:06:30.370 --> 00:06:32.690
contribute, but they hit a brick wall with

00:06:32.690 --> 00:06:36.690
so many unfamiliar topics all at once. What

00:06:36.690 --> 00:06:38.850
if Sam could ask for help finding some

00:06:38.850 --> 00:06:43.375
meaningful way to start participating? With Sam's permission,

00:06:43.615 --> 00:06:45.695
our AI, and let's assume it's a local

00:06:45.695 --> 00:06:47.775
AI, can build up a huge amount of

00:06:47.775 --> 00:06:50.975
context about their background. From old documents on

00:06:50.975 --> 00:06:53.215
Sam's hard drive, our AI knows all about

00:06:53.215 --> 00:06:55.600
their university coursework. It can see their current

00:06:55.600 --> 00:06:58.160
skills through work projects. It knows something about

00:06:58.160 --> 00:07:02.000
Sam's interests through their browsing history. So it

00:07:02.000 --> 00:07:04.160
suggests a few ideas, and Sam is excited

00:07:04.160 --> 00:07:06.240
about the idea of reproducing the paper's data

00:07:06.240 --> 00:07:08.400
analysis. That seems to play to their strengths.

00:07:09.765 --> 00:07:12.565
They notice that the authors use a custom

00:07:12.565 --> 00:07:14.805
Python package to do their analysis, but that

00:07:14.805 --> 00:07:17.525
code was never published. And that seems intriguing.

00:07:17.525 --> 00:07:20.405
Sam has built open source tools before. Maybe

00:07:20.405 --> 00:07:22.405
they could contribute here by building an open

00:07:22.405 --> 00:07:25.950
source version of this signal processing pipeline. So

00:07:25.950 --> 00:07:29.390
Sam dives in. They've found an open access

00:07:29.390 --> 00:07:32.270
dataset, and they've taken the first steps to

00:07:32.270 --> 00:07:35.950
start working with it. Tools like Copilot help

00:07:35.950 --> 00:07:38.030
Sam get started. But to follow some of

00:07:38.030 --> 00:07:40.185
these signal processing steps, what Sam really needs

00:07:40.185 --> 00:07:43.945
here is something like Copilot, but with awareness

00:07:43.945 --> 00:07:46.025
of the paper in addition to the code

00:07:46.185 --> 00:07:48.345
and with context about what Sam's actually trying

00:07:48.345 --> 00:07:52.985
to do. This AI system isn't trapped in

00:07:52.985 --> 00:07:55.110
its own chat box or in the sidebar

00:07:55.110 --> 00:07:57.590
of one application. It can see what's going

00:07:57.590 --> 00:08:00.310
on across multiple applications, and it can propose

00:08:00.310 --> 00:08:04.790
actions across multiple applications. Sam can click that

00:08:04.790 --> 00:08:07.430
button to view a change set with the

00:08:07.430 --> 00:08:10.945
potential implementation. Here that is. And then they

00:08:10.945 --> 00:08:13.985
can continue the conversation, smoothly switching into the

00:08:13.985 --> 00:08:17.105
context of the code editor. Like, what is

00:08:17.105 --> 00:08:21.745
this axis equals one parameter? The explanation depends

00:08:21.745 --> 00:08:24.670
on context from the code editor, from the

00:08:24.670 --> 00:08:27.470
paper being implemented, and also the documentation that

00:08:27.470 --> 00:08:29.470
came with the data set Sam's working with.

00:08:30.190 --> 00:08:33.630
The AI underlines assumptions made based on specific

00:08:33.630 --> 00:08:37.495
information and turns those things into links. So

00:08:37.495 --> 00:08:39.815
Sam can click on that in this dataset

00:08:39.815 --> 00:08:42.775
link, and our AI opens the ReadMe to

00:08:42.775 --> 00:08:46.135
the relevant line. All this is to support

00:08:46.135 --> 00:08:48.775
our central aim, which is that Sam can

00:08:48.775 --> 00:08:52.230
immerse themselves as much as possible in what

00:08:52.230 --> 00:08:55.110
they're actually trying to do, but get the

00:08:55.110 --> 00:08:57.830
support they need to understand what they're doing.

00:08:59.030 --> 00:09:00.790
And that support doesn't have to just mean

00:09:00.790 --> 00:09:05.365
text. Sam next needs to implement a downsampling

00:09:05.365 --> 00:09:09.605
stage. And this time, guidance includes synthesized dynamic

00:09:09.605 --> 00:09:12.645
media so that Sam can understand what downsampling

00:09:12.645 --> 00:09:16.520
does through scaffolded immersion. Doesn't need to read

00:09:16.520 --> 00:09:18.920
an abstract explanation and try to imagine what

00:09:18.920 --> 00:09:21.320
that would do to different signals. Instead, as

00:09:21.320 --> 00:09:23.560
they try different sampling rates, real time feedback

00:09:23.560 --> 00:09:25.720
can help them internalize the effect on different

00:09:25.720 --> 00:09:30.165
signals. By playing with the dynamic media, Sam

00:09:30.165 --> 00:09:31.685
notices that some of the peaks are lost

00:09:31.685 --> 00:09:36.245
when the signal is downsampled. These dynamic media

00:09:36.245 --> 00:09:39.285
aren't trapped in the chat box. They're using

00:09:39.285 --> 00:09:42.005
the same input data and libraries that Sam

00:09:42.005 --> 00:09:44.240
is using in their notebook. So at any

00:09:44.240 --> 00:09:46.640
time, Sam can just view source to tinker

00:09:46.640 --> 00:09:48.560
with this figure or to use some of

00:09:48.560 --> 00:09:55.360
its code in their own notebook. Now Sam

00:09:55.360 --> 00:10:00.045
presses on. But as they dig into bandpass

00:10:00.045 --> 00:10:03.165
filters, the high level explanations they can get

00:10:03.165 --> 00:10:06.125
from these short chat interactions really just don't

00:10:06.125 --> 00:10:09.805
feel like enough. What is a frequency domain?

00:10:10.045 --> 00:10:12.910
What is a Nyquist rate? Sam can copy

00:10:12.910 --> 00:10:15.150
and paste some AI generated code all day,

00:10:15.230 --> 00:10:17.230
but they don't understand what's going on at

00:10:17.230 --> 00:10:20.590
all. A chat interface is just not a

00:10:20.590 --> 00:10:24.670
great medium for long form conceptual explanation. It's

00:10:24.670 --> 00:10:29.045
time here for something deeper. Now, our AI

00:10:29.045 --> 00:10:31.765
knows Sam's background and aims here, so it

00:10:31.765 --> 00:10:34.645
suggests an appropriate undergraduate text with a practical

00:10:34.645 --> 00:10:38.805
focus. And more importantly, the AI reassures Sam

00:10:38.930 --> 00:10:41.490
that they don't necessarily need to read this

00:10:41.490 --> 00:10:45.410
entire thousand page book right now. It focuses

00:10:45.410 --> 00:10:48.130
on Sam's goal here and suggests a range

00:10:48.130 --> 00:10:50.930
of accessible paths that Sam can choose according

00:10:50.930 --> 00:10:52.690
to how deeply they would like to understand

00:10:52.690 --> 00:10:56.135
this material. The AI has made a personal

00:10:56.135 --> 00:10:58.775
map in the book's table of contents so

00:10:58.775 --> 00:11:00.855
that if Sam, for instance, just wants to

00:11:00.855 --> 00:11:03.895
understand what these filters are doing and why,

00:11:04.055 --> 00:11:06.535
there's a 25 page path for that. But

00:11:06.535 --> 00:11:08.375
if they want to know the mathematical background

00:11:08.375 --> 00:11:11.040
how these filters work, there's a deeper path.

00:11:11.040 --> 00:11:12.480
And if they want to actually be able

00:11:12.480 --> 00:11:15.440
to implement them themselves, there's an even deeper

00:11:15.440 --> 00:11:19.600
path. You can choose a journey here. When

00:11:19.600 --> 00:11:21.760
Sam digs into the book, you'll find notes

00:11:21.760 --> 00:11:23.360
from the AI at the start of each

00:11:23.360 --> 00:11:26.015
section and scattered throughout, which ground the material

00:11:26.015 --> 00:11:30.255
in Sam's context, Sam's project, Sam's purpose. This

00:11:30.255 --> 00:11:31.695
section will help you understand how to think

00:11:31.695 --> 00:11:34.255
about signals in terms of frequency spectra. That's

00:11:34.255 --> 00:11:38.360
what low pass filters manipulate. Sam is spending

00:11:38.360 --> 00:11:39.960
some time away from their project in a

00:11:39.960 --> 00:11:43.400
more traditionally instructional setting. But that doesn't mean

00:11:43.400 --> 00:11:45.640
the experience has to lose its connection to

00:11:45.640 --> 00:11:50.600
their authentic purpose. Incidentally, I've heard some technologists

00:11:50.600 --> 00:11:52.280
suggest that we should just use AI to

00:11:52.280 --> 00:11:55.505
synthesize the whole book. We'll get per person

00:11:55.505 --> 00:11:58.545
bespoke textbooks. But I think that there's actually

00:11:58.545 --> 00:12:00.625
a huge amount of value in having shared

00:12:00.625 --> 00:12:03.265
canonical artifacts. In any given field, there are

00:12:03.265 --> 00:12:05.185
key texts that we can all point to,

00:12:05.265 --> 00:12:06.705
and they form a common ground for the

00:12:06.705 --> 00:12:09.460
culture. I think we can preserve that by

00:12:09.460 --> 00:12:11.860
layering personalized context on top as a lens

00:12:11.860 --> 00:12:16.260
like this. In my ideal future, of course,

00:12:16.260 --> 00:12:19.540
our canonical shared artifacts are dynamic media, not

00:12:19.540 --> 00:12:23.035
digital representations of dead trees. But until all

00:12:23.035 --> 00:12:25.515
of our canonical works are rewritten as a

00:12:25.515 --> 00:12:27.835
transitional measure, we can at least wave our

00:12:27.835 --> 00:12:30.155
hands and imagine that our AI could synthesize

00:12:30.155 --> 00:12:32.795
dynamic media versions of figures like this one.

00:12:33.755 --> 00:12:35.780
Now, as Sam reads through the book, they

00:12:35.780 --> 00:12:37.300
can continue to engage with the text by

00:12:37.300 --> 00:12:40.260
asking questions as before, and our AI's responses

00:12:40.260 --> 00:12:42.660
will continue to be grounded in their project.

00:12:43.940 --> 00:12:46.420
As Sam highlights the text or makes comments

00:12:46.420 --> 00:12:48.980
about details which seem particularly important or surprising,

00:12:49.525 --> 00:12:52.005
those annotations won't end up trapped inside the

00:12:52.005 --> 00:12:54.965
PDF. Instead, they will feed into future discussions

00:12:54.965 --> 00:12:58.885
and practice, as we'll see later. In addition

00:12:58.885 --> 00:13:01.525
to Sam asking questions of the AI, the

00:13:01.525 --> 00:13:03.845
AI can insert questions for Sam to consider,

00:13:04.580 --> 00:13:07.460
again grounded in their project, to promote deeper

00:13:07.460 --> 00:13:11.140
processing of the material. And just as our

00:13:11.140 --> 00:13:13.460
AI guided Sam to the right sections of

00:13:13.460 --> 00:13:16.020
this thousand page book, it can point out

00:13:16.020 --> 00:13:18.740
which exercises might be most valuable, considering both

00:13:18.740 --> 00:13:23.355
Sam's background and their aims. Better, it can

00:13:23.355 --> 00:13:26.635
connect the exercises to Sam's aims so that

00:13:26.635 --> 00:13:30.555
aspirationally, doing those problems feels continuous with Sam's

00:13:30.555 --> 00:13:34.395
authentic practice. Even if the exercises do still

00:13:34.395 --> 00:13:37.970
feel somewhat decontextualized, Sam can at least feel

00:13:37.970 --> 00:13:39.730
more confident that the work is going to

00:13:39.730 --> 00:13:41.810
help them do what they want to do.

00:13:43.410 --> 00:13:45.890
So Sam ends the day with some rewarding

00:13:45.890 --> 00:13:48.690
progress on their project and a newfound understanding

00:13:48.690 --> 00:13:51.695
of quite a few topics. But this isn't

00:13:51.695 --> 00:13:55.855
yet robust knowledge. SAM has very little fluency.

00:13:55.855 --> 00:13:58.015
If they try to use this material seriously,

00:13:58.015 --> 00:14:00.175
they'll probably feel like they're standing on shaky

00:14:00.175 --> 00:14:04.820
ground. And more prosaically, they will probably forget

00:14:04.820 --> 00:14:08.500
much of what they just learned. So I'd

00:14:08.500 --> 00:14:09.700
like to focus on memory for a bit

00:14:09.700 --> 00:14:13.700
here. It's worth asking, why do we sometimes

00:14:13.700 --> 00:14:17.795
remember conceptual material and sometimes not? Often we

00:14:17.795 --> 00:14:20.275
take a class or read a book or

00:14:20.275 --> 00:14:22.755
even just look something up and find that

00:14:22.755 --> 00:14:25.555
a short time later, have retained almost nothing.

00:14:26.435 --> 00:14:28.835
But sometimes things seem to stick. Why is

00:14:28.835 --> 00:14:33.190
that? There are some easier cases. If you're

00:14:33.190 --> 00:14:34.630
learning something new in a domain that you

00:14:34.630 --> 00:14:36.950
know well, each new fact connects to lots

00:14:36.950 --> 00:14:39.670
of prior knowledge, and that creates more cues

00:14:39.670 --> 00:14:43.705
for recall and more opportunities for reinforcement. Likewise,

00:14:43.705 --> 00:14:45.385
if you're in some setting where you need

00:14:45.385 --> 00:14:47.705
that knowledge every single day, you will find

00:14:47.705 --> 00:14:51.145
that your memory becomes reliable pretty quickly. Conceptual

00:14:51.145 --> 00:14:53.865
material like what Sam just learned doesn't usually

00:14:53.865 --> 00:14:57.640
get reinforced every day like that. But sometimes

00:14:57.640 --> 00:15:00.520
the world conspires to give those memories the

00:15:00.520 --> 00:15:04.360
reinforcement it needs. Sometimes you read about a

00:15:04.360 --> 00:15:07.240
topic, and then later in that evening, that

00:15:07.240 --> 00:15:09.480
topic comes up in conversation with the collaborator.

00:15:10.775 --> 00:15:12.695
You have to retrieve what you learned, and

00:15:12.695 --> 00:15:16.055
that retrieval reinforces the memory. Then, maybe two

00:15:16.055 --> 00:15:18.375
days later, it comes up again. You need

00:15:18.375 --> 00:15:21.335
to recall that knowledge for a project. Each

00:15:21.335 --> 00:15:23.415
time you reinforce the memory this way, you

00:15:23.415 --> 00:15:26.210
forget it more slowly. Now perhaps a week

00:15:26.210 --> 00:15:27.890
can go by and you're still likely to

00:15:27.890 --> 00:15:30.610
remember, then maybe a few weeks, then a

00:15:30.610 --> 00:15:34.210
few months, and so on. With a surprisingly

00:15:34.210 --> 00:15:36.770
small number of retrievals, if they're placed close

00:15:36.770 --> 00:15:39.585
enough to avoid forgetting, you can retain that

00:15:39.585 --> 00:15:43.585
knowledge for months or years. By contrast, sometimes

00:15:43.585 --> 00:15:45.585
when you learn something, it doesn't come up

00:15:45.585 --> 00:15:48.225
again until, say, the next week. Then you

00:15:48.225 --> 00:15:50.065
try to retrieve the knowledge, but maybe it's

00:15:50.065 --> 00:15:52.305
already been forgotten. So you have to look

00:15:52.305 --> 00:15:54.790
it up. Looking it up doesn't reinforce your

00:15:54.790 --> 00:15:57.590
memory very much. And then if it doesn't

00:15:57.590 --> 00:15:59.510
come up again for a while longer, you

00:15:59.510 --> 00:16:01.590
may still not remember the next time. So

00:16:01.590 --> 00:16:03.510
you have to look it up again. And

00:16:03.510 --> 00:16:06.950
so on. The key insight here is that

00:16:06.950 --> 00:16:10.735
it's possible to arrange the timeline for yourself.

00:16:11.535 --> 00:16:15.215
And of course, courses sometimes do when each

00:16:15.215 --> 00:16:17.775
problem set consistently interleaves knowledge from the prior

00:16:17.775 --> 00:16:22.335
problem sets. But immersive learning and for that

00:16:22.335 --> 00:16:26.080
matter, most learning usually doesn't arrange this properly,

00:16:26.080 --> 00:16:29.680
so you usually forget a lot. What if

00:16:29.680 --> 00:16:32.160
this kind of reinforcement were woven into the

00:16:32.160 --> 00:16:37.325
grain of the learning region? Collaborator Michael Nielsen

00:16:37.325 --> 00:16:40.045
and I created a quantum computing primer, Quantum

00:16:40.045 --> 00:16:44.205
Country, to explore this idea. It's available for

00:16:44.205 --> 00:16:47.005
free online. If you head to quantum.country, you'll

00:16:47.005 --> 00:16:48.285
see what looks at first like a normal

00:16:48.285 --> 00:16:55.370
book. And after a few minutes of reading,

00:16:55.610 --> 00:16:58.250
the text is interrupted with a small set

00:16:58.250 --> 00:17:02.250
of review questions. They're designed to take just

00:17:02.250 --> 00:17:04.325
a few seconds each. Think the answer to

00:17:04.325 --> 00:17:06.725
yourself. Then mark whether or not you were

00:17:06.725 --> 00:17:10.085
able to answer correctly. And so far, these

00:17:10.085 --> 00:17:13.525
look like simple flashcards. But as we've discussed,

00:17:13.605 --> 00:17:15.605
even if you can answer these questions now,

00:17:15.605 --> 00:17:17.205
that doesn't mean you'll be able to in

00:17:17.205 --> 00:17:19.090
a few weeks or even in a few

00:17:19.090 --> 00:17:22.690
days. So notice these markings at the bottom

00:17:22.690 --> 00:17:26.450
of each question. These represent intervals. So you

00:17:26.450 --> 00:17:28.610
practice the questions while you're reading the text.

00:17:28.930 --> 00:17:30.770
Then one week later, you'll get an email

00:17:30.770 --> 00:17:32.850
that says, Hey, you have probably started to

00:17:32.850 --> 00:17:35.435
forget some of what you've learned. Do you

00:17:35.435 --> 00:17:37.195
want to take five minutes to quickly review

00:17:37.195 --> 00:17:40.635
that material again? Each time you answer successfully,

00:17:40.635 --> 00:17:43.035
the interval increases to a few weeks and

00:17:43.035 --> 00:17:45.355
a few months and so on. If you

00:17:45.355 --> 00:17:48.075
begin to forget, then the intervals tighten up

00:17:48.280 --> 00:17:51.000
to provide more reinforcement. Now you may have

00:17:51.000 --> 00:17:53.480
seen systems like this before. Language learners and

00:17:53.480 --> 00:17:55.800
medical students in particular often use tools called

00:17:55.800 --> 00:17:59.080
spaced repetition memory systems to remember vocabulary and

00:17:59.080 --> 00:18:02.725
basic facts. But the same cognitive mechanisms should

00:18:02.725 --> 00:18:05.845
work for more complex conceptual knowledge as well.

00:18:06.965 --> 00:18:10.245
There are 112 of these questions scattered throughout

00:18:10.245 --> 00:18:12.245
the first chapter of the book on that

00:18:12.245 --> 00:18:15.230
basis. Quantum country is a kind of new

00:18:15.230 --> 00:18:18.830
medium, a mnemonic medium, integrating a spaced repetition

00:18:18.830 --> 00:18:22.590
memory system with an explanatory text aspirationally to

00:18:22.590 --> 00:18:24.910
make it easier for people to absorb complex

00:18:24.910 --> 00:18:29.135
material reliably. We now have millions of practice

00:18:29.135 --> 00:18:30.895
data points, so we can start to see

00:18:30.895 --> 00:18:34.335
how well it's working. This plot shows the

00:18:34.335 --> 00:18:36.575
amount of time spent practicing on the x

00:18:36.575 --> 00:18:41.800
axis versus the reader's demonstrated retention that is,

00:18:41.800 --> 00:18:43.080
how long a reader was able to go

00:18:43.080 --> 00:18:45.800
without practicing and still answer at least 90%

00:18:45.800 --> 00:18:49.560
of questions correctly. These five dots represent the

00:18:49.560 --> 00:18:53.160
median user's first five repetitions for the first

00:18:53.160 --> 00:18:56.705
chapter. Notice that the y axis is logarithmic,

00:18:56.705 --> 00:18:59.025
so this straight line plot we're seeing here

00:18:59.025 --> 00:19:02.225
represents a very nice exponential growth. Each extra

00:19:02.225 --> 00:19:05.665
repetition, which is a constant extra time input,

00:19:05.665 --> 00:19:10.020
yields increasing output, I. E. Retention. And so

00:19:10.180 --> 00:19:12.180
in exchange for about an hour and a

00:19:12.180 --> 00:19:14.820
half of total practice, the median reader was

00:19:14.820 --> 00:19:17.780
able to correctly answer over 100 detailed questions

00:19:17.780 --> 00:19:20.100
about the first chapter after more than two

00:19:20.100 --> 00:19:23.975
months without any practice. Now, the first chapter

00:19:23.975 --> 00:19:26.535
takes most readers about four hours to read

00:19:26.535 --> 00:19:29.415
the first time. So this plot implies that

00:19:29.415 --> 00:19:32.135
an extra overhead of less than 50% in

00:19:32.135 --> 00:19:36.215
time commitment can yield months or years of

00:19:36.215 --> 00:19:40.080
detailed retention. It's also interesting to explore the

00:19:40.080 --> 00:19:43.200
counterfactual: how much would people have forgotten if

00:19:43.200 --> 00:19:46.240
they didn't have this extra reinforcement? So as

00:19:46.240 --> 00:19:48.880
an experiment, we removed nine questions from the

00:19:48.880 --> 00:19:51.425
first chapter for some readers and then covertly

00:19:51.425 --> 00:19:54.065
reinserted the questions one month later into their

00:19:54.065 --> 00:19:58.305
practice sessions. This graph shows what happened. These

00:19:58.305 --> 00:20:01.425
nine points represent those nine questions. The y

00:20:01.425 --> 00:20:03.505
axis shows the percentage of readers who are

00:20:03.505 --> 00:20:05.820
able to answer that correctly after one month

00:20:05.820 --> 00:20:08.300
with no support at all. You can see

00:20:08.300 --> 00:20:10.620
that some questions are harder than others. All

00:20:10.620 --> 00:20:12.140
the way over here on the left, one

00:20:12.140 --> 00:20:14.060
month later, the majority of readers missed the

00:20:14.060 --> 00:20:17.260
hardest three questions. And about thirty percent missed

00:20:17.260 --> 00:20:19.580
the middle three, about fifteen percent missed the

00:20:19.580 --> 00:20:23.555
easiest three. We can compare these to another

00:20:23.555 --> 00:20:25.875
group of users who got practice while reading

00:20:25.875 --> 00:20:27.475
the essay, like we saw in the video

00:20:27.475 --> 00:20:30.275
a moment ago. And for any questions they

00:20:30.275 --> 00:20:31.795
missed, they got a bonus round of practice

00:20:31.795 --> 00:20:34.515
the next day. Then these questions disappeared for

00:20:34.515 --> 00:20:37.910
a month, at which point we tested. These

00:20:37.910 --> 00:20:40.790
readers performed noticeably better, though a big chunk

00:20:40.790 --> 00:20:42.710
of them are still missing several of these

00:20:42.710 --> 00:20:46.870
questions. Now, here's one last group, like the

00:20:46.870 --> 00:20:49.685
previous one, except they got just one extra

00:20:49.685 --> 00:20:51.525
round of practice a week after reading the

00:20:51.525 --> 00:20:53.525
book. Then we tested them again at the

00:20:53.525 --> 00:20:54.805
one month mark, and that's what you're seeing

00:20:54.805 --> 00:20:58.485
here. Each question takes six seconds on average

00:20:58.485 --> 00:21:00.485
to answer. So this is less than a

00:21:00.485 --> 00:21:02.725
minute of extra practice in total for these

00:21:02.725 --> 00:21:05.120
nine questions. But now, for all of these

00:21:05.120 --> 00:21:07.200
questions, at least 90% of readers were able

00:21:07.200 --> 00:21:10.960
to answer correctly. Of course, some readers have

00:21:10.960 --> 00:21:14.400
a much easier time than others. So the

00:21:14.400 --> 00:21:17.200
left plot here focuses on the bottom quartile

00:21:17.200 --> 00:21:20.215
of users. That is, the readers who missed

00:21:20.215 --> 00:21:22.055
the most questions while they were first reading

00:21:22.055 --> 00:21:24.455
the essay. Notice that I've had to lengthen

00:21:24.455 --> 00:21:26.855
the y axis downwards here because we can

00:21:26.855 --> 00:21:29.735
see that without any practice at all, most

00:21:29.735 --> 00:21:31.735
of these people in the bottom quartile forgot

00:21:31.735 --> 00:21:35.730
two thirds of these held out questions. If

00:21:35.730 --> 00:21:39.490
they only had in essay practice, roughly half

00:21:39.490 --> 00:21:41.890
of them were left for getting roughly half

00:21:41.890 --> 00:21:45.810
of the questions. And here, with just one

00:21:45.810 --> 00:21:48.050
extra round of practice, that extra slightly less

00:21:48.050 --> 00:21:50.315
than a minute of extra practice, even this

00:21:50.315 --> 00:21:53.355
bottom quartile of readers performs quite well, almost

00:21:53.355 --> 00:21:59.195
as well as the overall population. So this

00:21:59.195 --> 00:22:02.315
is the power of practice efficient practice, at

00:22:02.315 --> 00:22:05.970
least. And this mechanism is useful for more

00:22:05.970 --> 00:22:09.570
than just quantum computing. In my personal practice,

00:22:09.570 --> 00:22:12.210
I have accumulated thousands and thousands of questions.

00:22:12.610 --> 00:22:15.890
I write questions about scientific papers, about conversations,

00:22:15.890 --> 00:22:19.155
about lectures, about memorable meals. I will definitely

00:22:19.155 --> 00:22:20.755
be writing a bunch about meetings I've had

00:22:20.755 --> 00:22:23.715
here today. All of this makes my daily

00:22:23.715 --> 00:22:26.835
life more rewarding because I know that if

00:22:26.835 --> 00:22:29.155
I invest my intention in something, I will

00:22:29.155 --> 00:22:33.000
internalize it indefinitely. Central to this is the

00:22:33.000 --> 00:22:36.200
idea of a daily ritual, a vessel for

00:22:36.200 --> 00:22:40.600
practice. Like meditation or exercise, I spend about

00:22:40.600 --> 00:22:42.680
ten minutes a day using this memory system.

00:22:43.815 --> 00:22:46.775
And because these exponential schedules are very efficient,

00:22:46.775 --> 00:22:49.255
those ten minutes are enough to maintain my

00:22:49.255 --> 00:22:51.895
memory for thousands of these questions and to

00:22:51.895 --> 00:22:53.815
allow me to add about 40 new questions

00:22:53.815 --> 00:22:58.650
every day. But there are some problems. So

00:22:58.650 --> 00:22:59.610
I want to mention a few of these

00:22:59.610 --> 00:23:04.250
problems. One is pattern matching. Once a question

00:23:04.250 --> 00:23:07.050
comes up a few times, I may recognize

00:23:07.050 --> 00:23:09.370
the text of the question without really thinking

00:23:09.370 --> 00:23:12.485
about its meaning. This creates the unpleasant feeling

00:23:12.485 --> 00:23:15.445
of parroting. But more importantly, I suspect it

00:23:15.445 --> 00:23:18.165
often leaves my memory brittle. I'll remember the

00:23:18.165 --> 00:23:21.045
answer, but only when queued exactly as I've

00:23:21.045 --> 00:23:23.765
practiced it. I wish the questions had more

00:23:23.765 --> 00:23:28.850
variability. Likewise, the questions are necessarily somewhat abstract.

00:23:29.570 --> 00:23:31.730
When I face a real problem in this

00:23:31.730 --> 00:23:34.930
domain, I won't always recognize what knowledge I

00:23:34.930 --> 00:23:36.690
should use or how to adapt it to

00:23:36.690 --> 00:23:39.835
that medium. A cognitive scientist would say maybe

00:23:39.835 --> 00:23:43.435
that I need to acquire schemas. Now, unless

00:23:43.435 --> 00:23:46.315
I intervene, these questions stay the same over

00:23:46.315 --> 00:23:49.595
years. They're maintaining my memory, but ideally they

00:23:49.595 --> 00:23:52.715
would push for further processing, increasing depth over

00:23:52.715 --> 00:23:57.250
time. And finally, returning to this talk's thesis,

00:23:57.330 --> 00:24:00.210
memory systems are too often disconnected from my

00:24:00.210 --> 00:24:03.730
authentic practice, what I'm actually interested in. Say

00:24:03.730 --> 00:24:05.730
I'm studying a topic in signal processing for

00:24:05.730 --> 00:24:10.065
a creative project. Unless I'm very careful, the

00:24:10.065 --> 00:24:11.985
questions that I get from that probably won't

00:24:11.985 --> 00:24:14.625
feel very connected to my project. They will

00:24:14.625 --> 00:24:17.665
probably feel like generic textbook questions about signal

00:24:17.665 --> 00:24:22.840
processing. Let's return to SAM now and see

00:24:22.840 --> 00:24:24.280
if we can apply some of these ideas

00:24:24.280 --> 00:24:27.960
about practice and memory. So Sam did the

00:24:27.960 --> 00:24:30.360
work to study that signal processing material. They

00:24:30.360 --> 00:24:32.360
want to make sure it actually sticks. How

00:24:32.360 --> 00:24:35.560
might that work? Let's say they can install

00:24:35.560 --> 00:24:39.115
a home screen widget, which ambiently exposes them

00:24:39.115 --> 00:24:43.275
to practice prompts drawn from highlights, questions asked,

00:24:43.355 --> 00:24:45.275
and any other activity that the AI can

00:24:45.275 --> 00:24:48.395
access. Sam can flip through these questions while

00:24:48.395 --> 00:24:51.220
waiting in line or on the bus. And

00:24:51.220 --> 00:24:53.940
notice that this isn't a generic textbook signal

00:24:53.940 --> 00:24:56.500
processing question. It's actually grounded in the details

00:24:56.500 --> 00:24:59.460
of Sam's brain computer interface project so that,

00:24:59.460 --> 00:25:02.740
at least aspirationally, practice feels somewhat more continuous

00:25:02.740 --> 00:25:08.655
with authentic doing. These synthesized prompts can vary

00:25:08.655 --> 00:25:10.815
each time they're asked so that Sam gets

00:25:10.815 --> 00:25:15.695
practice accessing the same idea from different angles.

00:25:18.540 --> 00:25:21.980
The prompts get deeper and more complex over

00:25:21.980 --> 00:25:24.460
time as Sam gets more confident with the

00:25:24.460 --> 00:25:28.300
material. Notice also that this question isn't so

00:25:28.300 --> 00:25:31.740
abstract. It's really about applying what Sam has

00:25:31.740 --> 00:25:34.245
learned in a bite sized form factor that

00:25:34.245 --> 00:25:38.325
can do anywhere. Now the widget can also

00:25:38.325 --> 00:25:41.685
include kind of more open ended discussion questions.

00:25:43.525 --> 00:25:45.365
Why do we think Metzger et al downsampled

00:25:45.365 --> 00:25:50.420
their signals to 200 Hertz? Maybe it's for

00:25:50.420 --> 00:25:55.620
performance? Here Sam gets some elaborative feedback and

00:25:55.620 --> 00:26:00.405
extra detail to consider in their answer. Now

00:26:00.405 --> 00:26:02.485
when questions are synthesized like this, it's important

00:26:02.485 --> 00:26:06.725
that Sam can steer them with feedback assuring

00:26:06.725 --> 00:26:09.845
that future questions are synthesized accordingly. Because again,

00:26:09.845 --> 00:26:11.285
what we're trying to do here is to

00:26:11.285 --> 00:26:13.445
make all of this not be homework, but

00:26:13.445 --> 00:26:15.570
to actually support what Sam is really trying

00:26:15.570 --> 00:26:19.250
to do. So far we've been looking at

00:26:19.250 --> 00:26:21.250
bite sized questions Sam can answer while they're

00:26:21.250 --> 00:26:23.410
out and about. But if they make time

00:26:23.410 --> 00:26:25.570
for a longer dedicated session, we can suggest

00:26:25.570 --> 00:26:29.055
meatier tasks like this one. And what's more,

00:26:29.055 --> 00:26:30.895
we can move that work out of fake

00:26:30.895 --> 00:26:34.335
practice land and into Sam's real context here

00:26:34.335 --> 00:26:37.775
at Jupyter Notebook. Notice that the task is

00:26:37.775 --> 00:26:40.335
still framed in terms of Sam's specific aims

00:26:40.335 --> 00:26:45.750
rather than some generic signal processing pipeline. Now,

00:26:45.750 --> 00:26:47.990
Sam got into this project not as a

00:26:47.990 --> 00:26:51.030
learning exercise, but as a way to start

00:26:51.030 --> 00:26:54.390
legitimately participating to start working with BCIs while

00:26:54.390 --> 00:26:57.705
playing to existing strengths. So just as our

00:26:57.705 --> 00:26:59.705
AI can help Sam find a tractable way

00:26:59.705 --> 00:27:02.265
into this space, it can also facilitate connections

00:27:02.265 --> 00:27:04.985
to communities of practice, here suggesting a local

00:27:04.985 --> 00:27:08.025
neurotech meetup. So let's say Sam goes to

00:27:08.025 --> 00:27:10.745
this meetup, meets a local scientist, and sets

00:27:10.745 --> 00:27:14.320
up a coffee date. With permission, Sam records

00:27:14.320 --> 00:27:16.960
the meeting, knowing the notes will probably be

00:27:16.960 --> 00:27:19.200
helpful later. And of course, Sam ends up

00:27:19.200 --> 00:27:21.840
surprised and intrigued quite a lot in this

00:27:21.840 --> 00:27:26.400
conversation. Our AI can notice these moments of

00:27:26.400 --> 00:27:30.945
surprise and help Sam metabolize them. Here, that

00:27:30.945 --> 00:27:36.865
insight turns into a reflective practice prompt. Four

00:27:36.865 --> 00:27:39.585
big design principles are threaded through Sam's story.

00:27:40.170 --> 00:27:41.770
I'd like to review them now, and for

00:27:41.770 --> 00:27:44.010
each, point out the ways that AI has

00:27:44.010 --> 00:27:48.730
helped me think about them. First, we bring

00:27:48.730 --> 00:27:52.650
guided learning to authentic contexts rather than thinking

00:27:52.650 --> 00:27:55.195
about it as a separate activity. We're able

00:27:55.195 --> 00:27:57.195
to make that happen by imagining an AI

00:27:57.195 --> 00:27:59.995
which can perceive and act across applications on

00:27:59.995 --> 00:28:03.195
Sam's computer. And as the audio transcript at

00:28:03.195 --> 00:28:05.435
the end of the story here alluded to,

00:28:05.915 --> 00:28:08.555
that action can potentially extend to activities outside

00:28:08.555 --> 00:28:11.830
of the computer as well. The AI can

00:28:11.830 --> 00:28:15.190
give appropriate guidance in part because, with permission

00:28:15.190 --> 00:28:17.910
and executing locally, it can learn from every

00:28:17.910 --> 00:28:20.230
piece of text that has ever crossed Sam's

00:28:20.230 --> 00:28:22.950
screen, every action they've ever taken on the

00:28:22.950 --> 00:28:27.635
computer. It can synthesize scaffolded dynamic media so

00:28:27.635 --> 00:28:30.195
that Sam can learn by doing, but with

00:28:30.195 --> 00:28:35.715
guidance. And then, when explicit learning activities are

00:28:35.715 --> 00:28:40.090
necessary, we suffuse them with authentic context. The

00:28:40.090 --> 00:28:42.970
AI in our story grounds all of the

00:28:42.970 --> 00:28:45.050
reading and practice Sam's doing in their actual

00:28:45.050 --> 00:28:48.410
aims. It helps Sam match the learning activities

00:28:48.410 --> 00:28:51.450
to their depth of interest. And it draws

00:28:51.450 --> 00:28:54.250
on important moments that happen while Sam is

00:28:54.250 --> 00:28:56.905
doing, like insights from that coffee meeting at

00:28:56.905 --> 00:28:59.865
the end or questions asked while implementing parts

00:28:59.865 --> 00:29:02.585
of the project. And it brings those moments

00:29:02.585 --> 00:29:07.225
into study activities. Besides connecting these two domains,

00:29:07.305 --> 00:29:11.400
we can also strengthen each of them. So

00:29:11.400 --> 00:29:14.360
our AI suggests tractable ways for Sam to

00:29:14.360 --> 00:29:17.800
just dive in to a new interest. And

00:29:17.800 --> 00:29:20.200
it helps Sam build connections with a community

00:29:20.200 --> 00:29:23.765
of practice. On the other side, when we

00:29:23.765 --> 00:29:26.085
are spending time in explicit learning activities, let's

00:29:26.085 --> 00:29:29.445
make sure that they actually work. So our

00:29:29.445 --> 00:29:32.725
AI creates a dynamic vessel for ongoing reinforcement.

00:29:33.605 --> 00:29:35.765
It varies what's in that vessel over time

00:29:35.790 --> 00:29:38.190
so that knowledge transfers more effectively to real

00:29:38.190 --> 00:29:42.270
situations. And it doesn't just maintain memory. It

00:29:42.270 --> 00:29:47.470
increases depth of understanding over time. Now I'd

00:29:47.470 --> 00:29:50.190
like to give two cheers for chatbot tutors.

00:29:51.095 --> 00:29:53.895
Most discussion of AI and education at the

00:29:53.895 --> 00:29:56.455
moment revolves around the framing of chatbot tutors.

00:29:56.455 --> 00:29:58.935
And I think this framing correctly identifies something

00:29:58.935 --> 00:30:01.655
really wonderful about language models, which is that

00:30:01.655 --> 00:30:03.815
they are so good at answering long tail

00:30:03.815 --> 00:30:06.610
questions if the user can articulate the question

00:30:06.610 --> 00:30:08.930
clearly enough. And if the user is trying

00:30:08.930 --> 00:30:11.570
to perform a routine task, chatbot tutors can

00:30:11.570 --> 00:30:14.130
often diagnose problems and find good ways to

00:30:14.130 --> 00:30:17.345
get the user unstuck. And that's great. But

00:30:17.345 --> 00:30:19.425
when I look at others' visions of chatbot

00:30:19.425 --> 00:30:21.985
tutors through the broader framing that we've been

00:30:21.985 --> 00:30:24.705
discussing, they're clearly missing a lot of what

00:30:24.705 --> 00:30:28.225
I want. I think these visions often fail

00:30:28.225 --> 00:30:29.665
to take seriously just how much a real

00:30:29.665 --> 00:30:32.160
tutor can really do. Large part, I think

00:30:32.160 --> 00:30:33.920
that's because the authors of these visions are

00:30:33.920 --> 00:30:37.680
usually thinking about educating, something they want to

00:30:37.680 --> 00:30:41.360
do to others rather than learning, something they

00:30:41.360 --> 00:30:44.715
want for themselves. Now a sad truth about

00:30:44.715 --> 00:30:46.795
the world is that postdocs and graduate students

00:30:46.795 --> 00:30:50.155
are incredibly underpaid. So it is actually surprisingly

00:30:50.155 --> 00:30:51.675
affordable to get an expert tutor for a

00:30:51.675 --> 00:30:55.115
technical topic I care about. But if I

00:30:55.115 --> 00:30:56.940
hire a real tutor as an adult to

00:30:56.940 --> 00:30:59.100
learn about signal processing, I will tell them

00:30:59.100 --> 00:31:01.420
about my interest in brain computer interfaces. And

00:31:01.420 --> 00:31:03.820
I will expect them to ground every conversation

00:31:03.820 --> 00:31:06.220
in that purpose. My goal here is not

00:31:06.220 --> 00:31:09.340
to learn signal processing. It is to participate

00:31:09.340 --> 00:31:12.495
in the creation of brain computer interfaces. Chatbot

00:31:12.495 --> 00:31:14.895
tutors are not interested in what I'm trying

00:31:14.895 --> 00:31:17.215
to do. There's a set of things they

00:31:17.215 --> 00:31:19.695
think I should know or should be able

00:31:19.695 --> 00:31:21.855
to do, and they view me as defective

00:31:21.855 --> 00:31:25.550
until I say the right things. If I

00:31:25.550 --> 00:31:27.390
hire a real tutor, I might ask them

00:31:27.390 --> 00:31:28.670
to sit beside me as I try to

00:31:28.670 --> 00:31:31.150
actually do something involving the material. They can

00:31:31.150 --> 00:31:32.990
see everything I'm doing, see what I'm pointing

00:31:32.990 --> 00:31:35.470
at. And if it's appropriate, I can scoot

00:31:35.470 --> 00:31:37.070
over and they can drive for a minute.

00:31:38.075 --> 00:31:40.395
By comparison, the typical conception of a chatbot

00:31:40.395 --> 00:31:43.755
tutor lives in a windowless box, and it

00:31:43.755 --> 00:31:45.755
can only see whatever's provided on scraps of

00:31:45.755 --> 00:31:48.155
paper passed under the door. It can have

00:31:48.155 --> 00:31:52.080
no effect on the outside world. My goal

00:31:52.080 --> 00:31:54.880
here is to dive in, to immerse myself,

00:31:54.880 --> 00:31:57.840
to start doing the thing. But these chatbot

00:31:57.840 --> 00:31:59.760
tutors can't join me where the action is.

00:32:00.640 --> 00:32:03.040
So interactions with them create distance and pull

00:32:03.040 --> 00:32:06.145
me away from immersion. If I hire a

00:32:06.145 --> 00:32:10.225
real tutor, we'll build a relationship. With every

00:32:10.225 --> 00:32:12.705
session, they'll learn more about me: my interests,

00:32:12.705 --> 00:32:15.985
my strengths, my confusions. Chatbot tutors, on the

00:32:15.985 --> 00:32:20.060
other hand, as typically conceived, are transactional, amnesiac.

00:32:20.780 --> 00:32:22.700
Now, we can fix that as context windows

00:32:22.700 --> 00:32:26.540
get longer. But that relationship is also important

00:32:26.540 --> 00:32:30.380
to my emotional connection. If I view conversation

00:32:30.380 --> 00:32:32.645
with my tutor as a kind of peripheral

00:32:32.645 --> 00:32:35.605
participation in the community I'm hoping to enter,

00:32:36.085 --> 00:32:38.085
an interaction between a novice in the discipline

00:32:38.085 --> 00:32:41.045
and an expert in the discipline, then tutoring

00:32:41.045 --> 00:32:44.160
just becomes part of doing the thing. But

00:32:44.160 --> 00:32:46.560
if my interaction with the tutor is transactional,

00:32:46.800 --> 00:32:48.480
that will tend to make my tutoring sessions

00:32:48.480 --> 00:32:52.160
feel like learning time, separate from doing the

00:32:52.160 --> 00:32:55.920
thing. Finally, people talk about how Aristotle was

00:32:55.920 --> 00:32:59.045
a tutor for Alexander the Great. But what's

00:32:59.045 --> 00:33:01.445
most valuable about having Aristotle as your tutor

00:33:01.445 --> 00:33:04.645
is not that he can diagnose misconceptions, but

00:33:04.645 --> 00:33:07.045
rather that he's modeling the practices and values

00:33:07.045 --> 00:33:11.250
of an earnest, intellectually engaged adult. He's demonstrating

00:33:11.250 --> 00:33:13.330
how and why he thinks about problems his

00:33:13.330 --> 00:33:16.450
taste and the discipline. The high growth periods

00:33:16.450 --> 00:33:18.370
that we love transform the way that we

00:33:18.370 --> 00:33:24.535
see the world. They reshape our identity. In

00:33:24.535 --> 00:33:26.455
my demo earlier, I showed a chatbot, but

00:33:26.455 --> 00:33:28.455
it didn't really work like most chatbot tutors

00:33:28.455 --> 00:33:31.895
I described. It focused all its actions on

00:33:31.895 --> 00:33:34.535
the user's interests rather than bringing its own

00:33:34.535 --> 00:33:36.855
agenda. It wasn't trapped in a little text

00:33:36.855 --> 00:33:40.070
box. It could see and take action in

00:33:40.070 --> 00:33:42.790
the context of authentic use. It can communicate

00:33:42.790 --> 00:33:45.190
through dynamic media. It had a deep memory

00:33:45.190 --> 00:33:47.830
drawing on everything I'd ever seen and written.

00:33:48.310 --> 00:33:50.150
So in some ways, the system I've shown

00:33:50.150 --> 00:33:53.350
is more like a real tutor. But in

00:33:53.350 --> 00:33:55.430
my ideal world, I don't want a tutor.

00:33:56.135 --> 00:33:58.935
I want to legitimately participate in some new

00:33:58.935 --> 00:34:01.095
discipline and learn what I need as much

00:34:01.095 --> 00:34:04.695
as possible from interaction with real practitioners. So

00:34:04.695 --> 00:34:06.935
I view the role of the augmented learning

00:34:06.935 --> 00:34:10.080
system as helping me act on my creative

00:34:10.080 --> 00:34:12.480
interests, ideally by letting me just dive in

00:34:12.480 --> 00:34:15.920
and start doing as much as possible. That

00:34:15.920 --> 00:34:18.480
will often mean scaffolding connections to and interactions

00:34:18.480 --> 00:34:23.295
with communities of practice. One theme for this

00:34:23.295 --> 00:34:25.855
Design at Large series is the ethics of

00:34:25.855 --> 00:34:29.215
AI and its likely enormous social impacts. So

00:34:29.215 --> 00:34:30.895
let me say, I am tremendously worried about

00:34:30.895 --> 00:34:33.135
those impacts in the general case. I am

00:34:33.135 --> 00:34:35.950
worried about despots locking in their powers. Lowering

00:34:35.950 --> 00:34:39.790
the bar to bioweapons, economic chaos. I would

00:34:39.790 --> 00:34:43.070
not feel comfortable ethically with researching more powerful

00:34:43.070 --> 00:34:47.790
frontier models myself. But within the narrower domain

00:34:47.790 --> 00:34:50.115
of learning that we've been discussing, my main

00:34:50.115 --> 00:34:52.355
moral concern is that we will end up

00:34:52.355 --> 00:34:57.315
trapped in a sad, narrow future. A condescending

00:34:57.315 --> 00:35:00.675
authoritarian frame dominates the narrative in the future

00:35:00.675 --> 00:35:03.580
of learning. I'll caricature it to make the

00:35:03.580 --> 00:35:07.020
point. With AI, we can finally take all

00:35:07.020 --> 00:35:08.700
of these defective kids that don't know the

00:35:08.700 --> 00:35:10.860
stuff they're supposed to know and get them

00:35:10.860 --> 00:35:13.740
to know it. You know, that's personalized learning.

00:35:13.740 --> 00:35:16.060
The AI lets us precisely identify where the

00:35:16.060 --> 00:35:18.585
kids are wrong or where they're ignorant and

00:35:18.585 --> 00:35:20.905
fix them. Then we can fill their heads

00:35:20.905 --> 00:35:22.665
to the brim with what's good for them.

00:35:24.185 --> 00:35:26.425
By contrast, the famous bicycle for the mind

00:35:26.425 --> 00:35:29.225
metaphor has no agenda other than the one

00:35:29.225 --> 00:35:31.720
that you bring. It just lets you reach

00:35:31.720 --> 00:35:33.480
a wider range of destinations than you could

00:35:33.480 --> 00:35:35.240
on foot, and it makes the journey more

00:35:35.240 --> 00:35:37.480
fun, maybe particularly if you're biking along with

00:35:37.480 --> 00:35:40.120
some friends. The bicycle asks, Where do you

00:35:40.120 --> 00:35:43.720
want to go? Of course, that question assumes

00:35:43.720 --> 00:35:46.775
your destination is well known and charted on

00:35:46.775 --> 00:35:50.375
some map. But those most rewarding, high growth

00:35:50.375 --> 00:35:53.735
experiences are often centered on a creative project.

00:35:54.135 --> 00:35:55.495
You're trying to get somewhere no one's ever

00:35:55.495 --> 00:35:57.895
gone before to reach the frontier and then

00:35:57.895 --> 00:36:01.670
starting charting links into the unknown. Learning in

00:36:01.670 --> 00:36:05.830
service of creation. It's a dynamic, context laden

00:36:05.830 --> 00:36:08.630
kind of learning. It's about more than just

00:36:08.630 --> 00:36:12.390
efficiency and correctness. More than just faster gears

00:36:12.390 --> 00:36:14.805
on a bike. And that's the kind of

00:36:14.805 --> 00:36:17.045
learning that I feel an almost moral imperative

00:36:17.045 --> 00:36:28.550
to help create. Thank you. I think we

00:36:28.550 --> 00:36:30.470
maybe have time for questions. We have some

00:36:30.470 --> 00:36:38.790
time for questions. Love to talk. Thank you.

00:36:38.790 --> 00:36:40.470
I really like a lot of what you

00:36:40.470 --> 00:36:42.305
said. One thing that I'm curious about is

00:36:42.305 --> 00:36:45.425
you mentioned that you add questions to your

00:36:45.425 --> 00:36:49.105
own, like for your space repetition routine, you

00:36:49.105 --> 00:36:51.025
add questions every And you said you add

00:36:51.025 --> 00:36:53.345
40 questions a day. So I guess what

00:36:53.345 --> 00:36:55.910
I'm wondering is, in your example you took

00:36:55.910 --> 00:36:58.630
one topic, but many people are often learning

00:36:58.630 --> 00:37:01.190
multiple things. And very often we don't know

00:37:01.190 --> 00:37:03.670
that we want to learn something until we've

00:37:03.670 --> 00:37:06.790
built some momentum. So my question is broadly,

00:37:06.790 --> 00:37:08.390
how do you decide what questions you want

00:37:08.390 --> 00:37:11.645
to add and how do you plan for

00:37:11.645 --> 00:37:13.885
your future self in some way? Right, right.

00:37:13.885 --> 00:37:16.445
First, should clarify. So I don't, in fact,

00:37:16.445 --> 00:37:19.085
add 40 questions a day. That is the

00:37:19.085 --> 00:37:23.005
carrying capacity of my practice time. Ten minutes

00:37:23.005 --> 00:37:25.970
will support 40 a day added. In practice,

00:37:25.970 --> 00:37:27.650
it ends up like some kind of Poisson

00:37:27.650 --> 00:37:31.170
distribution or something. But how do I do

00:37:31.170 --> 00:37:33.490
this? How do I plan appropriately? You can't

00:37:33.490 --> 00:37:35.650
know what's going to be important to you

00:37:35.650 --> 00:37:38.850
in advance. Sometimes you can, but in general

00:37:38.850 --> 00:37:41.615
you can't. So the system needs to be

00:37:41.615 --> 00:37:44.095
resilient to that. The way that that works

00:37:44.095 --> 00:37:47.135
right now is very coarse. You can delete

00:37:47.135 --> 00:37:48.895
questions that you add if you decide that

00:37:48.895 --> 00:37:51.135
you don't like them. I view this as

00:37:51.135 --> 00:37:53.295
an interface problem of sorts. I think ideally

00:37:53.295 --> 00:37:55.140
you don't need to plan for what's going

00:37:55.140 --> 00:37:57.300
to be important. You can just do stuff,

00:37:57.540 --> 00:37:59.540
and stuff will get reinforced, and you can

00:37:59.540 --> 00:38:02.820
steer more of this, less of that. And

00:38:03.860 --> 00:38:06.580
I think that's an interesting challenge in interface

00:38:06.580 --> 00:38:08.420
design to create systems that behave more like

00:38:08.420 --> 00:38:10.495
that and less like these kind of discrete

00:38:10.495 --> 00:38:15.615
destructive actions destroy this question. Andy, I love

00:38:15.615 --> 00:38:19.615
that vision over here for that. Especially liked

00:38:19.615 --> 00:38:22.015
how you talked about how the AI could

00:38:22.015 --> 00:38:25.450
reinforce things you've learned and challenge you. It

00:38:25.450 --> 00:38:28.170
could integrate you with communities. Love all those

00:38:28.410 --> 00:38:30.810
ideas. What I didn't get, and maybe I

00:38:30.810 --> 00:38:33.290
guess I walked in two minutes late, was

00:38:33.290 --> 00:38:36.810
that an actual demo that you've created? No.

00:38:36.810 --> 00:38:38.650
Or is that just a vision for how

00:38:38.650 --> 00:38:39.875
you want it to be in the future?

00:38:39.875 --> 00:38:42.275
Yeah, I'm sorry for not making that clear.

00:38:42.355 --> 00:38:43.715
If it wasn't, I thought it looked sufficiently

00:38:43.715 --> 00:38:47.635
fake. No, this is concept art. Thank you

00:38:47.635 --> 00:38:50.515
for asking. There is, I suppose, a grand

00:38:50.515 --> 00:38:52.835
tradition in our discipline of smoke and mirror

00:38:52.835 --> 00:38:56.740
concept art. I have been using this talk

00:38:56.740 --> 00:38:58.660
as an excuse to figure out what I

00:38:58.660 --> 00:39:02.180
think I want to do with respect to

00:39:02.180 --> 00:39:05.540
AI and learning. And so these drawings are

00:39:05.540 --> 00:39:11.735
part of that process. I was curious, I

00:39:11.735 --> 00:39:15.655
wanted to follow-up on the question about sometimes

00:39:15.655 --> 00:39:17.575
I don't know what I want. And I

00:39:17.575 --> 00:39:19.255
think if you look at some of the

00:39:19.255 --> 00:39:25.450
more Montessori or Papert esque learning experiences, when

00:39:25.450 --> 00:39:28.730
you know when you have like, you know,

00:39:28.730 --> 00:39:30.010
if you just said school is gonna be

00:39:30.010 --> 00:39:32.890
whatever you're interested in forever. Yeah. It has

00:39:32.890 --> 00:39:38.825
lots of benefits. A challenge is that there

00:39:38.825 --> 00:39:41.465
are topics that I might benefit from, and

00:39:41.465 --> 00:39:44.985
I loved your paternalistic caricature as being that's

00:39:44.985 --> 00:39:48.710
what we don't want. There is a, like,

00:39:48.710 --> 00:39:52.870
the psychologist Dan Gilbert defines the happiness challenge

00:39:52.870 --> 00:39:56.150
as the delta between our current self and

00:39:56.150 --> 00:39:58.230
what our future self would have wanted us

00:39:58.230 --> 00:40:01.510
to do. I can, like a nice thing

00:40:01.510 --> 00:40:04.695
about a good tutor, your talk for example,

00:40:04.935 --> 00:40:07.175
is I'm learning things that will be valuable

00:40:07.175 --> 00:40:09.415
to me in the future that at 04:00

00:40:09.415 --> 00:40:11.975
today I wouldn't have thought to ask for.

00:40:11.975 --> 00:40:14.615
Right. Yeah, yeah, I think this is totally

00:40:14.615 --> 00:40:16.350
right. I think the way that I think

00:40:16.350 --> 00:40:18.430
about this is a kind of unbundling. Normally

00:40:18.430 --> 00:40:20.510
when we think about schooling, we ask schooling

00:40:20.510 --> 00:40:22.670
to do two jobs: one, to decide what

00:40:22.670 --> 00:40:23.950
is it that I should know and then

00:40:23.950 --> 00:40:26.670
two, to cause me to know it. I

00:40:26.670 --> 00:40:28.750
think there are all kinds of cultural institutions

00:40:29.055 --> 00:40:30.415
that help us figure out what is it

00:40:30.415 --> 00:40:32.975
that we want to know. In the example

00:40:32.975 --> 00:40:34.735
that I showed, Sam figures out that they

00:40:34.735 --> 00:40:36.975
may be interested in brain computer interfaces through

00:40:36.975 --> 00:40:40.175
Twitter. If you are in San Diego, you

00:40:40.175 --> 00:40:42.850
can decide to attend this talk. Ideally, it

00:40:42.850 --> 00:40:44.290
doesn't feel like schooling. Hope it doesn't feel

00:40:44.290 --> 00:40:45.970
like schooling. And you can decide, oh, maybe

00:40:45.970 --> 00:40:47.730
I'm interested in studying some of the cognitive

00:40:47.730 --> 00:40:50.370
science that Andy mentioned. So I think there's

00:40:50.370 --> 00:40:53.650
a variety of cultural institutions and venues and

00:40:53.650 --> 00:40:56.370
channels we can use to help deliver that

00:40:56.450 --> 00:41:01.495
first part, and then possibly use separate tools

00:41:01.495 --> 00:41:07.575
for the other part. Good afternoon. Should we

00:41:07.575 --> 00:41:09.895
be planning for the day where we won't

00:41:09.895 --> 00:41:14.190
have to work due to artificial intelligence, automation,

00:41:14.350 --> 00:41:18.830
computers and robotics? Your thoughts. Thank you. I'm

00:41:18.830 --> 00:41:20.430
so grateful that you asked that question because

00:41:20.430 --> 00:41:22.270
I spent a month preparing for this talk,

00:41:23.710 --> 00:41:26.030
writing another version of this talk that I

00:41:26.030 --> 00:41:28.305
didn't give that was called What's Worth Learning

00:41:28.305 --> 00:41:31.185
in the Age of Strong AI? And it

00:41:31.185 --> 00:41:32.865
didn't end up aligning, so I didn't end

00:41:32.865 --> 00:41:35.505
up getting to present any of it. I'll

00:41:35.505 --> 00:41:40.100
give you a piece of that. Say that

00:41:40.100 --> 00:41:45.140
you are a composer, and you have some

00:41:45.140 --> 00:41:47.540
very vague idea about a new cello concerto

00:41:47.540 --> 00:41:50.580
that you would like to write. I claim

00:41:50.580 --> 00:41:52.340
that you can't just ask the AI to

00:41:52.340 --> 00:41:55.035
write it for you, because you don't know

00:41:55.275 --> 00:41:57.595
what it is that you want. In fact,

00:41:57.595 --> 00:41:59.115
you discover what the cello concerto is supposed

00:41:59.115 --> 00:42:01.275
to be through the process of composing it.

00:42:01.995 --> 00:42:06.155
Likewise, when we talk about software. An interesting

00:42:06.155 --> 00:42:08.860
thing about software is that it feels so

00:42:08.860 --> 00:42:10.540
messy and unpleasant so much of the time.

00:42:10.540 --> 00:42:12.620
We want a particular piece of software. We

00:42:12.620 --> 00:42:14.060
ask some people to go start making it

00:42:14.060 --> 00:42:16.460
for us. And then they come back 3x

00:42:16.460 --> 00:42:19.500
over time, 3x over budget, one third x

00:42:19.500 --> 00:42:21.660
quality. Why is software so hard? Why can't

00:42:21.660 --> 00:42:24.595
we just tell the system what we want

00:42:24.835 --> 00:42:27.555
and get the thing out the other side?

00:42:27.635 --> 00:42:29.795
And it turns out we actually do have

00:42:30.115 --> 00:42:32.355
that kind of technology. It's called formal modeling.

00:42:32.355 --> 00:42:34.115
We've had it for a long time. And

00:42:34.115 --> 00:42:35.395
I think the reason why it's not more

00:42:35.395 --> 00:42:37.370
widely used is that that's not how we

00:42:37.370 --> 00:42:40.730
think about designing software. Namely, we figure out

00:42:40.730 --> 00:42:42.650
what software we want in the process of

00:42:42.650 --> 00:42:47.530
making it. It's continuously negotiated. It's contingent. So

00:42:47.530 --> 00:42:49.850
I think there are many activities in human

00:42:49.850 --> 00:42:52.395
life that have that characteristic where we can't

00:42:52.395 --> 00:42:54.555
actually appropriately specify what it is that we

00:42:54.555 --> 00:42:56.155
want to the model. We can't externalize it

00:42:56.155 --> 00:42:58.395
or make it legible. We have to participate

00:42:58.395 --> 00:43:00.555
in the creation of the thing. And then

00:43:00.555 --> 00:43:01.755
we can ask, what do we need to

00:43:01.755 --> 00:43:03.675
know in order to participate in that creation?

00:43:03.675 --> 00:43:05.595
What are the dynamics of that participation? How

00:43:05.595 --> 00:43:08.680
much injection of involvement is necessary to steer

00:43:08.680 --> 00:43:12.360
appropriately. And I have some thoughts on that,

00:43:12.360 --> 00:43:13.880
but I should probably move on to the

00:43:13.880 --> 00:43:16.200
next question. So yes, I hope that's somewhat

00:43:16.200 --> 00:43:23.545
helpful. Yeah. Hi. So with my question, I

00:43:23.545 --> 00:43:25.625
was thinking about how with the AI, what

00:43:25.625 --> 00:43:28.025
you have is you like say that AI

00:43:28.025 --> 00:43:30.345
advancement will lead to some dystopian feature where

00:43:30.345 --> 00:43:31.865
we find people the knowledge and then we

00:43:31.865 --> 00:43:34.060
force them to know it. But who's to

00:43:34.060 --> 00:43:35.580
say that that is still already happening to

00:43:35.580 --> 00:43:37.980
some extent with curriculum right now without AI?

00:43:39.420 --> 00:43:41.500
Isn't necessarily a concern as much as other

00:43:41.500 --> 00:43:43.420
things, I think. But beyond that, I think

00:43:43.420 --> 00:43:46.140
it's kind of like, because that problem can

00:43:46.140 --> 00:43:47.795
happen, like when we don't look at the

00:43:47.795 --> 00:43:49.955
root problem, it can happen in the most

00:43:49.955 --> 00:43:52.915
immersive learning. In ethnic studies class you can

00:43:52.915 --> 00:43:55.315
still end up restricting someone to that specific

00:43:55.315 --> 00:43:57.475
topic instead of connecting identity as much as

00:43:57.475 --> 00:43:58.995
you would in say a math class or

00:43:58.995 --> 00:44:01.420
something like that. So what if you could

00:44:01.420 --> 00:44:05.020
implement that like sort of, I guess to

00:44:05.020 --> 00:44:07.260
give another example of how in the other

00:44:07.260 --> 00:44:09.580
hand, you can do something really well, even

00:44:09.580 --> 00:44:11.420
in a math class, for example, if you

00:44:11.420 --> 00:44:13.020
look at the higher concepts or if someone

00:44:13.020 --> 00:44:14.865
explains it really well, or in like say

00:44:14.865 --> 00:44:17.265
neuroscience and those sorts of fields, there might

00:44:17.265 --> 00:44:19.265
be content that is above the cost that

00:44:19.265 --> 00:44:21.425
is interesting that would make someone more interested

00:44:21.425 --> 00:44:23.985
and able to learn the class themselves, especially

00:44:23.985 --> 00:44:25.985
if it connects to their own prior knowledge.

00:44:25.985 --> 00:44:29.730
So what would you think if like, guess,

00:44:29.730 --> 00:44:31.170
how do you think you would implement this

00:44:31.170 --> 00:44:33.410
into like a learning system to take advantage

00:44:33.410 --> 00:44:35.090
of it like say Canvas? Do you think

00:44:35.090 --> 00:44:36.130
that you could do it in a way

00:44:36.130 --> 00:44:38.930
that you could customize in part assignments to

00:44:38.930 --> 00:44:41.810
synthesize the students' interests and the teachers' intent

00:44:42.015 --> 00:44:44.895
to teach people necessary content and teach people

00:44:44.895 --> 00:44:46.975
the content that they want to know in

00:44:46.975 --> 00:44:48.895
a way that they might be doing more,

00:44:48.895 --> 00:44:50.975
but ultimately less because it's easier for them

00:44:50.975 --> 00:44:52.975
if they know the context and can connect

00:44:52.975 --> 00:44:56.540
to it. Cool. I think I followed. So

00:44:56.540 --> 00:44:58.940
to your first question, yeah, I think you're

00:44:58.940 --> 00:45:06.300
right. That part of the talk was part

00:45:06.300 --> 00:45:08.780
of a complaint about schooling in general. And

00:45:10.585 --> 00:45:13.705
AI doesn't necessarily make that worse, though it

00:45:13.705 --> 00:45:17.225
may continue trends I don't like. To your

00:45:17.225 --> 00:45:20.825
second point, or your second question, I have

00:45:20.825 --> 00:45:24.825
deliberately avoided the question of schooling in this

00:45:24.825 --> 00:45:28.560
talk. And I did that for a reason.

00:45:28.560 --> 00:45:30.960
I think it makes everything very complicated. So

00:45:30.960 --> 00:45:36.160
in terms of integrating into Canvas, I think

00:45:36.960 --> 00:45:40.675
it's a very difficult position to start. I

00:45:40.675 --> 00:45:43.715
have done a bunch of collaborations these past

00:45:43.715 --> 00:45:48.835
few years with professors in higher ed teaching

00:45:48.915 --> 00:45:52.435
large classes. And what I experience again and

00:45:52.435 --> 00:45:56.360
again is just an enormous fraction of the

00:45:56.360 --> 00:45:59.240
student body that is just fundamentally not engaged

00:45:59.240 --> 00:46:02.040
with the class. And I don't think any

00:46:02.040 --> 00:46:06.680
amount of UI chicanery or AI involvement is

00:46:06.680 --> 00:46:09.965
going to change that. And I think I

00:46:09.965 --> 00:46:11.725
basically don't want to put myself into that

00:46:11.725 --> 00:46:14.045
problem solving situation. In some sense, that's actually

00:46:14.045 --> 00:46:19.085
why I left Khan Academy. Hey, Andy. My

00:46:19.085 --> 00:46:20.765
name's Taylor. I'm a software engineer at Replit.

00:46:20.765 --> 00:46:23.800
So I would say, in some sense, my

00:46:23.800 --> 00:46:25.640
salary depends on some of the ideas in

00:46:25.640 --> 00:46:27.480
your talk, which is to say that AI

00:46:27.480 --> 00:46:29.800
can be an effective tool for teaching difficult

00:46:29.800 --> 00:46:33.480
concepts like computer programming. So my question to

00:46:33.480 --> 00:46:37.640
you is, have you seen any inklings of

00:46:37.945 --> 00:46:40.505
this being true, the ideas in your talk

00:46:41.225 --> 00:46:44.105
of the delta between something like a GBT,

00:46:44.905 --> 00:46:47.385
being a teacher, and what you're outlining? Have

00:46:47.385 --> 00:46:50.745
you seen any of those ideas actually start

00:46:50.745 --> 00:46:52.180
to play out? Or do you think this

00:46:52.180 --> 00:46:54.260
is purely speculative with what we have today?

00:46:54.260 --> 00:46:57.860
Yeah. I think we're seeing a lot of

00:46:57.860 --> 00:47:02.580
hints at what I described already. So lots

00:47:02.580 --> 00:47:05.975
of people already use GPT to just dive

00:47:05.975 --> 00:47:10.135
into stuff. It's missing that universal IO. It's

00:47:10.135 --> 00:47:13.815
missing the billion token context window. And yet

00:47:13.815 --> 00:47:16.855
it's still already able to deliver some value,

00:47:17.980 --> 00:47:20.460
which is great. I think missing also that

00:47:20.460 --> 00:47:24.300
the bridge to textbooks again and again, I've

00:47:24.300 --> 00:47:26.380
been talking to people not that textbooks are

00:47:26.380 --> 00:47:28.380
the answer. Here I'm using textbook as synecdoche

00:47:28.380 --> 00:47:31.180
for some kind of deeper, more focused learning

00:47:31.820 --> 00:47:33.905
experience. I talk to a lot of people

00:47:33.905 --> 00:47:38.225
who get a really good start with GPT

00:47:38.225 --> 00:47:40.705
because they can get the couple sentence answers,

00:47:40.705 --> 00:47:42.065
and that lets them make a certain amount

00:47:42.065 --> 00:47:43.745
of progress. And that's really motivating. You can

00:47:43.745 --> 00:47:45.665
kick up some momentum, and momentum is very

00:47:45.665 --> 00:47:49.560
powerful. But they hit a wall. And I

00:47:49.560 --> 00:47:51.880
had a section that I cut talking about

00:47:51.880 --> 00:47:54.120
programming. I think it's really interesting that in

00:47:54.120 --> 00:47:56.920
programming, a lot of people can manage to

00:47:56.920 --> 00:47:59.560
self teach programming. And in part, I think

00:47:59.560 --> 00:48:02.755
that's because of things like syntax, for instance,

00:48:02.755 --> 00:48:04.835
is reinforced every time you sit down to

00:48:04.835 --> 00:48:08.675
program. Obscure facets of syntax, which are not

00:48:08.675 --> 00:48:11.635
reinforced regularly, like maybe your macro library or

00:48:11.635 --> 00:48:17.710
whatever, people do tend to forget. But again

00:48:17.710 --> 00:48:19.470
and again you meet people who are like,

00:48:20.270 --> 00:48:22.910
I don't understand how pointers work though. That

00:48:22.910 --> 00:48:24.830
asterisk can see. It's like it's a bridge

00:48:24.830 --> 00:48:26.750
too far. So there's a certain amount of

00:48:26.750 --> 00:48:30.350
conceptual understanding that seems acquirable with the frontier

00:48:30.350 --> 00:48:32.590
of self learning tools that are widely available.

00:48:32.955 --> 00:48:34.875
And then as soon as you run into

00:48:34.875 --> 00:48:37.995
difficult conceptual territory, it's just a cliff. So

00:48:37.995 --> 00:48:41.675
I think we're seeing glimmers of progress in

00:48:41.675 --> 00:48:44.555
this vein, and perhaps this talk will inspire

00:48:44.555 --> 00:48:50.520
people to try some more stuff. Hello. Hi.

00:48:50.920 --> 00:48:53.880
So my question is, to what extent do

00:48:53.880 --> 00:48:57.000
you think the desire to learn comes from

00:48:57.000 --> 00:48:59.960
the innate pleasure of learning or specific to

00:48:59.960 --> 00:49:02.165
whatever material the person learning is? And to

00:49:02.165 --> 00:49:04.245
what extent do you think the desire to

00:49:04.245 --> 00:49:07.205
learn comes from some sort of use of

00:49:07.205 --> 00:49:09.045
the material the person learns? And do you

00:49:09.045 --> 00:49:14.165
think making this distinction is important to the

00:49:14.165 --> 00:49:18.410
design of systems for learning? Yeah, probably. This

00:49:18.410 --> 00:49:20.970
is a good question, and it's something that

00:49:20.970 --> 00:49:24.810
I don't emphasize perhaps quite clearly enough. In

00:49:24.810 --> 00:49:28.330
the example story that I gave, everything is

00:49:28.330 --> 00:49:32.115
motivated by this persona, Sam, wanting to do

00:49:32.115 --> 00:49:33.875
a project. It's very concrete. It's out in

00:49:33.875 --> 00:49:38.595
the world. That doesn't mean that curiosity based

00:49:38.595 --> 00:49:41.475
learning is any less legitimate or that I

00:49:41.475 --> 00:49:43.315
think any of the claims don't apply. It's

00:49:43.315 --> 00:49:46.490
just that what authentic practice and legitimate participation

00:49:46.490 --> 00:49:50.010
looks like is different. So in mathematics, for

00:49:50.010 --> 00:49:51.610
instance, which may be very abstract, it may

00:49:51.610 --> 00:49:53.130
not be like a project I'm trying to

00:49:53.130 --> 00:49:55.290
do as I learn about algebraic topology or

00:49:55.290 --> 00:49:58.465
something like that, What legitimate practice looks like

00:49:58.465 --> 00:50:02.465
is engaging with problems and questions in algebraic

00:50:02.465 --> 00:50:07.985
topology that I find authentically interesting. And as

00:50:07.985 --> 00:50:09.665
soon as you make that move, rather than

00:50:09.665 --> 00:50:11.345
thinking about, well, I need to learn algebraic

00:50:11.160 --> 00:50:13.080
topology in order to do this four d

00:50:13.080 --> 00:50:14.680
renderer that I was working on for a

00:50:14.680 --> 00:50:16.920
game project, if you think about it from

00:50:16.920 --> 00:50:19.240
the perspective of authentic curiosity, then I think

00:50:19.240 --> 00:50:24.605
much of what I'm saying applies. However, there

00:50:24.605 --> 00:50:28.605
are issues with rendering legible the nature of

00:50:28.605 --> 00:50:31.165
the curiosity and the interest to the AI.

00:50:31.885 --> 00:50:34.365
A lot of what's happening is internal, and

00:50:34.365 --> 00:50:35.565
that may make a lot of what I'm

00:50:35.565 --> 00:50:40.480
describing somewhat more difficult. The nature of relation

00:50:40.480 --> 00:50:43.360
to community of practices changes somewhat, although not

00:50:43.360 --> 00:50:47.920
completely. So it's a partial answer, I suppose.

00:50:48.080 --> 00:50:50.240
Is there someone with the microphone? Hi, Jonathan.

00:50:50.240 --> 00:50:54.885
Hi, Andy. This is great. Love the deepness

00:50:54.885 --> 00:50:58.485
of the reflective practice you're demonstrating for us

00:50:57.605 --> 00:51:02.885
I think, is it Aristotle that said, give

00:51:02.885 --> 00:51:04.725
me a child till the age of seven

00:51:04.725 --> 00:51:07.700
and I'll show you the man? And when

00:51:07.700 --> 00:51:09.860
you bring up the ethical issues, this is

00:51:09.860 --> 00:51:12.900
what scares me the most is for an

00:51:12.900 --> 00:51:21.735
AI tutor. Have you thought about adversarial tutoring?

00:51:22.935 --> 00:51:24.855
Given that we're going to have, if we

00:51:24.855 --> 00:51:27.495
do, if we hypothesize AI tutors are out

00:51:27.495 --> 00:51:29.895
there and that we have the schooling industrial

00:51:29.895 --> 00:51:34.530
complex producing them, how do we counteract them?

00:51:35.490 --> 00:51:39.890
I love that. It's like manufacturing the mythical

00:51:39.890 --> 00:51:42.370
and often in the teaching community maligned Robin

00:51:42.370 --> 00:51:47.330
Williams character, the teacher film whose name I'm

00:51:47.330 --> 00:51:51.195
forgetting. I haven't thought about that. It's a

00:51:51.195 --> 00:51:58.315
lovely provocation. I feel uncomfortable with an activist

00:51:58.315 --> 00:52:00.315
framing, where it's like, I need to get

00:52:00.315 --> 00:52:02.640
out there because I know what's best for

00:52:02.640 --> 00:52:04.880
the people or for the kids. They're doing

00:52:04.880 --> 00:52:06.480
it wrong. I'm going make a thing that's

00:52:06.480 --> 00:52:08.800
going to put fluoride in the drinking water

00:52:08.800 --> 00:52:11.520
so that they end up in the right

00:52:11.520 --> 00:52:17.625
spot. I'm uncomfortable with that. I feel much

00:52:17.625 --> 00:52:19.545
more comfortable saying, well, I can make a

00:52:19.545 --> 00:52:20.745
thing that lets you pursue the things you're

00:52:20.745 --> 00:52:23.225
interested in, if you would like that. That

00:52:23.225 --> 00:52:27.065
feels less complicated. So I will need to

00:52:27.065 --> 00:52:29.225
think about your question. Find it very provocative.

00:52:29.225 --> 00:52:36.060
Thank you. Hey, Andy. I have a question

00:52:36.060 --> 00:52:40.380
for you about this idea of that AI

00:52:40.380 --> 00:52:44.140
tutor. I'm wondering, is there a limit to

00:52:44.515 --> 00:52:46.915
what kind of disciplines that that course kind

00:52:46.915 --> 00:52:49.555
of technology could be applied to? I've always

00:52:49.555 --> 00:52:52.755
deemed myself as being book smarts but not

00:52:52.755 --> 00:52:57.235
street smarts. That's a great question. One of

00:52:57.235 --> 00:53:00.630
the inspirations for this talk was trying to

00:53:00.630 --> 00:53:05.270
exorcise myself of the young ladies illustrated primer.

00:53:05.270 --> 00:53:06.630
I don't know if that phrase means anything

00:53:06.630 --> 00:53:09.510
to you. Ah, that's a shame. Okay, so

00:53:09.590 --> 00:53:13.095
an inspiration for many educational technologists is this

00:53:13.095 --> 00:53:15.095
book called The Diamond Age by Neal Stephenson,

00:53:15.175 --> 00:53:18.695
which depicts a sort of far future utopian

00:53:18.695 --> 00:53:23.175
learning environment. It's like a magical book that

00:53:23.175 --> 00:53:25.950
transforms a young girl's life. And one of

00:53:25.950 --> 00:53:27.790
the things that's interesting about this book that

00:53:27.790 --> 00:53:29.310
I think is underappreciated is that it is

00:53:29.310 --> 00:53:32.110
almost exclusively focused on street smarts. So this

00:53:32.110 --> 00:53:34.430
book teaches her martial arts and getting out

00:53:34.430 --> 00:53:36.750
of sticky situations and persuading people and so

00:53:36.750 --> 00:53:41.285
on. And I chose not to deal with

00:53:41.285 --> 00:53:45.445
any of that. I think the way that

00:53:45.445 --> 00:53:49.685
I would handle much of that looks very

00:53:49.685 --> 00:53:53.640
different. And I'm afraid I haven't really thought

00:53:53.640 --> 00:53:58.040
about how I would handle that. It's difficult

00:53:58.040 --> 00:54:01.880
to think about authentic practice of street smarts.

00:54:02.200 --> 00:54:04.440
Like what does that look like? Is it

00:54:04.440 --> 00:54:07.155
like I'm going to go to a bad

00:54:07.155 --> 00:54:09.715
neighborhood and like look purposeful as I walk?

00:54:10.035 --> 00:54:12.755
And then but that's not exactly authentic practice

00:54:12.755 --> 00:54:14.275
because like you went to this neighborhood just

00:54:14.275 --> 00:54:17.315
for that purpose. So I find myself confused

00:54:17.315 --> 00:54:21.990
thinking about this. And I find myself most

00:54:21.990 --> 00:54:26.470
comfortable when I think about people who enjoy

00:54:26.470 --> 00:54:29.590
practicing martial arts not as a kind of

00:54:29.590 --> 00:54:35.835
preparatory measure for imagined conflict in the future,

00:54:35.835 --> 00:54:37.515
but rather because they like the way it

00:54:37.515 --> 00:54:39.355
makes their body feel. They like their community

00:54:39.355 --> 00:54:43.115
at the dojo. And so if we start

00:54:43.115 --> 00:54:45.970
thinking about that, like, oh, it would be

00:54:45.970 --> 00:54:49.250
fun to do some exercise with others, then

00:54:49.250 --> 00:54:50.850
I think some of the same techniques can

00:54:50.850 --> 00:54:53.650
help. So you can probably use tools to

00:54:53.650 --> 00:54:56.530
help you find an appropriate community and perhaps

00:54:56.530 --> 00:54:58.690
to help you practice appropriately. I play the

00:54:58.690 --> 00:55:02.335
piano. And that's not exactly book smart, but

00:55:02.335 --> 00:55:05.615
one can use practice systems, vessels for practice

00:55:05.615 --> 00:55:09.535
like I've described, to orchestrate piano practice. You

00:55:09.535 --> 00:55:11.695
can imagine extending that to martial arts. I

00:55:11.695 --> 00:55:13.535
don't know about other kinds of street smarts,

00:55:13.775 --> 00:55:16.940
but perhaps. Thanks for the question. Let's thank

00:55:16.940 --> 00:55:18.780
Andy, and I'm sure he'll stay around a

00:55:18.780 --> 00:55:23.980
few little. Thanks everybody. Appreciate you.
